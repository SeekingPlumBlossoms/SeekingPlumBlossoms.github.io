{"pages":[],"posts":[{"title":"Android手机支付宝客户端刷新session问题","text":"表述问题: 支付宝android客户端在H5请求服务后端接口时，无法维持会话，导致后端服务器一直在重复获取用户信息，猜测原因:支付宝Android客户端内置浏览器内核问题。 解决方案 前端改造 前端使用JSONP的方式请求后端 在回调的方法中获取Auth_code以及后端返回的sessionId 后续每次请求都需要带上sessionId以保证会话的唯一性 后端改造 处理sessionId从header中获取 123456789 /** * 使用Header进行传输 * * @return */@Beanpublic HttpSessionIdResolver httpSessionIdResolver() { return new HeaderHttpSessionIdResolver(\"x-auth-token\");}","link":"/2019/03/13/Android手机支付宝客户端刷新session问题/"},{"title":"Long.getLong()与Long.valueOf()的区别","text":"前言 最近在线上的日志出现了一些”java.lang.NullPointerException”,本着线上不应该出现这种空指针异常的问题,我去追踪了代码，记录下这个坑，防止后续继续踩坑. 前因 因为调用接口会有失败的可能，所以在调用接口失败后，需要休眠主线程，等待一段时间后，继续进行调用。 编写代码 需求不是很难,于是很快潇潇洒洒的写下的如下代码： 1234567 String times = \"300\";long timeL = Long.getLong(times);try { Thread.sleep(timeL);} catch (InterruptedException e) { e.printStackTrace();} 后续 就是这段简单的代码出现了错误：java.lang.NullPointerException 分析 getLong方法源码 1234567891011121314public static Long getLong(String nm, Long val) { String v = null; try { v = System.getProperty(nm); } catch (IllegalArgumentException | NullPointerException e) { } if (v != null) { try { return Long.decode(v); } catch (NumberFormatException e) { } } return val; } System.getProperty(nm)这个方法是获取系统的属性值 valueOf源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public static long parseLong(String s, int radix) throws NumberFormatException { if (s == null) { throw new NumberFormatException(\"null\"); } if (radix &lt; Character.MIN_RADIX) { throw new NumberFormatException(\"radix \" + radix + \" less than Character.MIN_RADIX\"); } if (radix &gt; Character.MAX_RADIX) { throw new NumberFormatException(\"radix \" + radix + \" greater than Character.MAX_RADIX\"); } long result = 0; boolean negative = false; int i = 0, len = s.length(); long limit = -Long.MAX_VALUE; long multmin; int digit; if (len &gt; 0) { char firstChar = s.charAt(0); if (firstChar &lt; '0') { // Possible leading \"+\" or \"-\" if (firstChar == '-') { negative = true; limit = Long.MIN_VALUE; } else if (firstChar != '+') throw NumberFormatException.forInputString(s); if (len == 1) // Cannot have lone \"+\" or \"-\" throw NumberFormatException.forInputString(s); i++; } multmin = limit / radix; while (i &lt; len) { // Accumulating negatively avoids surprises near MAX_VALUE digit = Character.digit(s.charAt(i++),radix); if (digit &lt; 0) { throw NumberFormatException.forInputString(s); } if (result &lt; multmin) { throw NumberFormatException.forInputString(s); } result *= radix; if (result &lt; limit + digit) { throw NumberFormatException.forInputString(s); } result -= digit; } } else { throw NumberFormatException.forInputString(s); } return negative ? result : -result; } 总结 getLong方法是获取到系统属性之后,decode这个字符串返回了； valueOf 才是真正的装换方法 编写完成以后，需要进行单元测试，不要放过任何可疑的代码。","link":"/2019/01/23/Long-getLong-与Long-valueOf-的区别/"},{"title":"CAP理论记录","text":"序常听说CA,CP,AP,为了不使自己忘记这些定义,特此记录完整的CAP理论。 一、CAP理论的定义 Consistency (一致性)： “all nodes see the same data at the same time”,即更新操作成功并返回客户端后，所有节点在同一时间的数据完全一致，这就是分布式的一致性。一致性的问题在并发系统中不可避免，对于客户端来说，一致性指的是并发访问时更新过的数据如何获取的问题。从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致。 Availability (可用性): 可用性指”Reads and writes always succeed”，即服务一直可用，而且是正常响应时间。好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。 Partition Tolerance (分区容错性): 即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。 分区容错性要求能够使应用虽然是一个分布式系统，而看上去却好像是在一个可以运转正常的整体。比如现在的分布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求，对于用户而言并没有什么体验上的影响。 二、CAP理论证明1).为什么不能同时满足三个特性如下图所示：2个请求Q1,Q2,分别对应查询数据库DB1，DB2；正常情况下，DB1向DB2同步数据，所以在正常情况下Q1,Q2这2个分别获取到的数据是一致的。假如，DB1向DB2同步是出现网络异常，我们要兼容这种情况，因为要有分区容错性；那么此时就会出现2中情况。 DB2直接返回旧的数据给Q2，这样就保证了可用性，但是牺牲了数据一致性。 DB2阻塞等待DB1同步数据，这样就保证了数据一致性，但是牺牲了可用性。 所以在上述的过程中，说明了：在满足分布式分区容错的前途下，只能在一致性和可用性两者中，选择其中一个。 三、CAP的取舍规则 CA without P 如果系统不要求进行p(不容许分区),那么CA是可以保证的.但是放弃P就意味着放弃了系统的扩展性，也就是分布式节点受限，这违背了分布式系统设计的初衷。 CP without A 如果没有A(可用性),相当于每个请求都需要在服务器之间保持强一致，而P(分区容错)会导致同步等待的时间无限延长(需要等待数据完全同步完成才能进行正常访问),一旦发生网络情况，就需要牺牲用户体验。 CP的系统有:分布式数据库(redis、hbase等)，这些系统要求数据的强一致性。 AP without C 如果要做到HA(高可用),并且容许分区,则需要放弃一致性。一旦分区发生，节点之间就会失去联系，为了高可用，每个节点只能用本地数据提供服务，这样会导致全局数据的不一致性。 四、总结总而言之，没有最好的策略，好的系统应该是根据业务场景来进行架构设计的，只有适合的才是最好的。","link":"/2019/05/06/CAP理论记录/"},{"title":"JDK提供的四种线程池","text":"序本文为了梳理下线程池的概念以及基础的使用。 一、什么是线程1.1线程的定义线程(Thread):操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。 1.2线程的状态 新线程态（New Thread)产生一个Thread对象就生成一个新线程。当线程处于”新线程”状态时，仅仅是一个空线程对象，它还没有分配到系统资源。因此只能启动或终止它。任何其他操作都会引发异常。例如，一个线程调用了new方法之后，并在调用start方法之前的处于新线程状态，可以调用start和stop方法。 可运行态（Runnable)start（）方法产生运行线程所必须的资源，调度线程执行，并且调用线程的run（）方法。在这时线程处于可运行态。该状态不称为运行态是因为这时的线程并不总是一直占用处理机。特别是对于只有一个处理机的PC而言，任何时刻只能有一个处于可运行态的线程占用处理机。Java通过调度来实现多线程对处理机的共享。注意，如果线程处于Runnable状态，它也有可能不在运行，这是因为还有优先级和调度问题。 阻塞/非运行态（Not Runnable)当以下事件发生时，线程进入非运行态。 suspend()方法被调用； sleep()方法被调用； 线程使用wait()来等待条件变量； 线程处于I/O请求的等待。 死亡态（Dead)当run（）方法返回，或别的线程调用stop（）方法，线程进入死亡态。通常Applet使用它的stop（）方法来终止它产生的所有线程 二、什么是线程池线程池是一种典型的“空间换时间”的应用案例。在线程池中维护一定数量的线程池，在每次有有请求过来的时候，不需要每次都去创建新的线程，而是从线程池中选出可用的线程,这样做的代价是线程即使是空闲的时候也会占用系统的资源。 三、为什么用线程池 线程池内线程可以重复使用 减少创建和销毁线程所带来的系统资源的开销 提升吞吐量，提升了性能 四、JDK提供的四种线程池使用方式4.1固定线程数的线程池（newFixedThreadPool）这种线程池里面的线程被设计成存放固定数量的线程，具体线程数可以考虑为CPU核数*N（N可大可小，取决于并发的线程数，计算机可用的硬件资源等）。以下是获取CPU核数： int processors = Runtime.getRuntime().availableProcessors(); FixedThreadPool 是通过 java.util.concurrent.Executors 创建的 ThreadPoolExecutor 实例。这个实例会复用 固定数量的线程处理一个共享的无边界队列 。任何时间点，最多有 nThreads 个线程会处于活动状态执行任务。如果当所有线程都是活动时，有多的任务被提交过来，那么它会一致在队列中等待直到有线程可用。如果任何线程在执行过程中因为错误而中止，新的线程会替代它的位置来执行后续的任务。所有线程都会一致存于线程池中，直到显式的执行 ExecutorService.shutdown() 关闭。由于阻塞队列使用了LinkedBlockingQueue，是一个无界队列，因此永远不可能拒绝任务。LinkedBlockingQueue在入队列和出队列时使用的是不同的Lock，意味着他们之间不存在互斥关系，在多CPU情况下，他们能正在在同一时刻既消费，又生产，真正做到并行。因此这种线程池不会拒绝任务，而且不会开辟新的线程，也不会因为线程的长时间不使用而销毁线程。这是典型的生产者—-消费者问题，这种线程池适合用在稳定且固定的并发场景. 4.2缓存的线程池（newCachedThreadPool）核心池大小为0，线程池最大线程数目为最大整型，这意味着所有的任务一提交就会加入到阻塞队列中。当线程池中的线程60s没有执行任务就终止，阻塞队列为SynchronousQueue。SynchronousQueue的take操作需要put操作等待，put操作需要take操作等待，否则会阻塞（线程池的阻塞队列不能存储，所以当目前线程处理忙碌状态时，所以开辟新的线程来处理请求），线程进入wait set。总结下来：①这是一个可以无限扩大的线程池；②适合处理执行时间比较小的任务；③线程空闲时间超过60s就会被杀死，所以长时间处于空闲状态的时候，这种线程池几乎不占用资源；④阻塞队列没有存储空间，只要请求到来，就必须找到一条空闲线程去处理这个请求，找不到则在线程池新开辟一条线程。如果主线程提交任务的速度远远大于CachedThreadPool的处理速度，则CachedThreadPool会不断地创建新线程来执行任务，这样有可能会导致系统耗尽CPU和内存资源，所以在使用该线程池是，一定要注意控制并发的任务数，否则创建大量的线程可能导致严重的性能问题。 4.3单个线程的线程池（newSingleThreadExecutor）SingleThreadExecutor是使用单个worker线程的Executor，作为单一worker线程的线程池，SingleThreadExecutor把corePool和maximumPoolSize均被设置为1，和FixedThreadPool一样使用的是无界队列LinkedBlockingQueue,所以带来的影响和FixedThreadPool一样。对于newSingleThreadExecutor()来说，也是当线程运行时抛出异常的时候会有新的线程加入线程池替他完成接下来的任务。创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行，所以这个比较适合那些需要按序执行任务的场景。比如：一些不太重要的收尾，日志等工作可以放到单线程的线程中去执行。日志记录一般情况会比较慢（数据量大一般可能不写入数据库），顺序执行会拖慢整个接口，堆积更多请求，还可能会对数据库造成影响（事务在开启中），所以日志记录完全可以扔到单线程的线程中去，一条条的处理，也可以认为是一个单消费者的生产者消费者模式。 4.4固定个数的线程池（newScheduledThreadPool）相当于第一个固定线程的问题,此线程可以执行延时任务，也可以执行带有返回值的任务。","link":"/2019/06/03/JDK提供的四种线程池/"},{"title":"Nacos之基于springBoot注册中心的整合","text":"序接入上篇的内容，本次主要说明Nacos作为注册中心的用法,并且是使用dubbo使用注解的方式进行访问。 开始搭建之旅 新建maven工程并且在其中新建2个SringBoot2.X的工程，如下图所示 开始提供者provider的工程搭建 引入Maven依赖123456789101112131415161718192021222324252627&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo-registry-nacos&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;4.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Dubbo dependency --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.5&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Alibaba Spring Context extension --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.spring&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-discovery-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.1&lt;/version&gt;&lt;/dependency&gt; 在Application.properties中添加如下配置 12345678910111213## applicationdubbo.application.name = dubbo-provider-demo## Nacos registry addressdubbo.registry.id = dubboRegistrydubbo.registry.address = ****Nacos****:8848dubbo.registry.protocol=nacos## Dubbo Protocoldubbo.protocol.id = dubbodubbo.protocol.name = dubbodubbo.protocol.port = 20880# Provider @Service versiondemo.service.version=1.0.0demo.service.name = demoService 注意：其中：Nacos为Nacos服务器地址，Naocs的部署的方式需要为集群方式 如果出现以下错误 1java.lang.IllegalStateException: No such extension com.alibaba.dubbo.registry.RegistryFactory by name nacos 这个错误的意思是：Dubbo的注册协议找不到Nacos类型的实现类。原因分析如下:dubbo2.5.6没有引入注册到Nacos实现类 需要加入新jar 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo-registry-nacos&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/dependency&gt; 问题解决！！！ 新建一个实现类ProviderServiceImpl继承ProviderServicem,里面只有一个方法sayHello：1234567@Service(registry = \"dubboRegistry\",version = \"1.0\",group = \"providerDemo\",owner = \"yebin\",timeout = 5000)public class ProviderServiceImpl implements ProviderService {@Overridepublic String sayHello(String name) { return \"***** OH ， My God!~~~~\" + name + \",天下无敌，唯我独尊~~~~!!! *****\"; }} 生产者启动类配置，需要加上EnableDubbo注解123456789101112@SpringBootApplication@EnableDubbo(scanBasePackages = \"com.nacos.provider.demo\")public class ProviderApplication {public static void main(String[] args) throws IOException { SpringApplication.run(ProviderApplication.class, args); System.out.println(\"DemoService provider is starting...\"); //程序等待不关闭 System.in.read(); }} 消费者配置文件同提供者一致，消费测试如下 12345678910111213@Componentpublic class ConsumeService { @Reference(version = \"1.0\",group = \"providerDemo\",registry = \"dubboRegistry\") ProviderService providerService; @PostConstruct public void initData(){ for(int i = 0; i &lt; 10; i++){ System.out.println(providerService.sayHello(\"叶宾\")); } }} 启动测试,先启动生产者,在启动消费者,出现如下截图，表示成功 总结整合Nacos+SpringBoot+Dubbo完成了,后续会继续总结下原理，不能总停留在用上，要走上道的意义。 友情链接：(大佬)SnoWalker’s Blog","link":"/2019/03/20/Nacos之基于springBoot注册中心的整合/"},{"title":"Nacos之基于springBoot配置中心的整合","text":"序接入上篇的内容，本次主要说明Nacos作为配置中心的用法,实现动态刷新获取值。 开始接入Nacos作为配置中心 新建springBoot2.X版本，引入以下依赖 12345 &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-discovery-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.1&lt;/version&gt;&lt;/dependency&gt; 在application.properties引入server-addr地址 因为我的Nacos本地启动所以配置信息如下 1nacos.config.server-addr=localhost:8848 在启动类PivasApplication上加上NacosPropertySource和EnableNacosConfig注解 配置信息如下 1234567891011121314151617181920212223/** * @author yebin */@SpringBootApplication@NacosPropertySource(dataId = \"com.yb.data\", groupId = \"yb\", autoRefreshed = true)@RestController@EnableNacosConfig()public class PivasApplication { public static void main(String[] args) throws Exception { SpringApplication.run(PivasApplication.class, args); } /** * key=hello 默认值是dd autoRefreshed表示是否自动刷新 */ @NacosValue(value = \"${hello:dd}\", autoRefreshed = true) private String hello; @GetMapping(\"/test\") public String test() { return \"hello \" + hello; }} 名称解释： 引用阿里云的定义： dataId: Nacos 中的某个配置集的 ID。配置集 ID 是组织划分配置的维度之一。Data ID 通常用于组织划分系统的配置集。一个系统或者应用可以包含多个配置集，每个配置集都可以被一个有意义的名称标识。Data ID 通常采用类 Java 包（如 com.taobao.tc.refund.log.level）的命名规则保证全局唯一性。此命名规则非强制。 group: Nacos 中的一组配置集，是组织配置的维度之一。通过一个有意义的字符串（如 Buy 或 Trade ）对配置集进行分组，从而区分 Data ID 相同的配置集。当您在 Nacos 上创建一个配置时，如果未填写配置分组的名称，则配置分组的名称默认采用 DEFAULT_GROUP 。配置分组的常见场景：不同的应用或组件使用了相同的配置类型，如 database_url 配置和 MQ_topic 配置。 在Nacos后台配置进行配置 验证成果:访问如下地址 ：http://localhost:18080/test 页面出现hello world表示成功 总结整合期间，出现了数据一致取不到的问题，最后发现没有@EnableNacosConfig()导致，有兴趣可以看下里面的配置项。后续会出具体Nacos作为注册中心的整合. 友情链接：(大佬)SnoWalker’s Blog","link":"/2019/03/20/Nacos之基于springBoot配置中心的整合/"},{"title":"com.mysql.cj.jdbc.Driver与com.mysql.jdbc.Driver区别","text":"前言springboot2.x整合myBatis时，工程正常运行，数据正常，但是在日志中出现了一个红红的东西:1Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary. 意思是说：com.mysql.jdbc.Driver这个数据库驱动已经过时，需要更换成新的驱动：com.mysql.cj.jdbc.Driver，本着工程一片绿的想法，我将驱动改成了com.mysql.cj.jdbc.Driver server time zone时区问题经过上述步骤之后,出现了新的问题:12345678910java.sql.SQLException: The server time zone value '' is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the serverTimezone configuration property)to use a more specifc time zone value if you want to utilize time zone support. at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:127) at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:95) at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:87) at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:61) ... 原因:未配置正确的是时区解决方案 在mysql链接串后面直接加上时区，例如: 配置信息： 1jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=GMT%2B8 serverTimezone分析 com.mysql.jdbc.Driver 是 mysql-connector-java 5中的; com.mysql.cj.jdbc.Driver 是 mysql-connector-java 6以上中的 我们需要设定为东八区，也就是上海所在的时区，也可以直接指定东八区 修改数据库的配置 12show variables like '%time_zone%'set global time_zone='+8:00';","link":"/2019/03/15/com-mysql-cj-jdbc-Driver与com-mysql-jdbc-Driver区别/"},{"title":"Nacos之部署","text":"一、什么是NacosNacos是阿里巴巴开源的一款支持服务注册与发现，配置管理以及微服务管理的组件。 Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。 Nacos 是构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。 Nacos gitHub : https://github.com/alibaba/nacos Nocos 文档 ：https://nacos.io/zh-cn/docs/what-is-nacos.html 二、开始搭建Nacos 去GitHub地址：https://github.com/alibaba/nacos/releases 下载 下面以 1.0.0-RC1(Mar 15, 2019) 为例： 页面的底部有如下下载地址： 任选其中一个连接进行下载 本文以nacos-server-1.0.0-rc1.zip为例 解压本地到本地，解压，进入bin目录 如果是windows启动，则cmd下面执行，startup.cmd即启动Nacos 如果是linux启动，则执行startup.sh即行 本地运行服务Nocas 导入工程项目：下载地址 *git@github.com:alibaba/nacos.git*: 新建数据库名称为Nacos,配置在 nacos-default.properties 文件路径：console目录下 修改内容： 12345db.num=1db.url.0=jdbc:mysql://localhost:3306/nacoss?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true#db.url.1=jdbc:mysql://11.163.152.91:3306/diamond_devtest?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=rootdb.password=123456 在新建Nacos数据库中执行sql 文件路径：config目录下 文件名：nacos-db.sql 配置cluster.conf文件内容： 123#it is ip#example172.30.83.85（本机IP） 执行console下的Nacos方法： 登陆地址：http://172.30.83.85:8848/nacos/index.html 初始账号：admin 初始密码：admin 注意：Nacos需要使用JDK8 总结 今天只是总结了Nacos的搭建方式，后续会更新springBoot结合Nacos作为服务中心和配置中心的使用 友情链接：(大佬)SnoWalker’s Blog","link":"/2019/03/19/Nacos之部署/"},{"title":"docker下删除两个id相同的镜像","text":"前言今天在删除废弃docker镜像的时候,有2个相同镜像Id的容器在启动，在执行命令docker rmi +镜像Id 失败 镜像如下图所示： 执行命令出现如下错误： Error response from daemon: conflict: unable to delete 1e3cf999044d (must be forced) - image is referenced in one or more repositories 错误原因： 有2个相同1e3cf999044d的镜像，所以不能删除 删除的办法：使用repository和tag进行操作的,执行如下命令 docker rmi repository/tag 进行删除， repository/tag是上图中标红部分 友情链接：(大佬)SnoWalker’s Blog","link":"/2019/03/18/docker下删除两个id相同的镜像/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2018/06/03/hello-world/"},{"title":"代码扫描工具","text":"前言作为一个程序员,需要对自己的代码进行CR,提前找到自己代码中的坏味道或者漏洞;先介绍如下几种代码扫描工具 sonar使用步骤1. 启动sona 地址：E:\\sonarqube-6.7.4\\bin 选择对应的环境执行 2. 登陆http://localhost:9000/ 3. 在工作空间执行 mvn sonar:sonar 4. 对比文档进行修改 FindBugs使用步骤1. 如图下载FindBUgs插件 使用说明邮件点击工程项目,然后点击FIndBugs执行扫描 【提示】 至此，findBugs安装完毕，但有个问题，在验证是否安装成功的时候发现，重新启动eclipse后并没有findBugs功能，经过查询分析，问题出在版本上，在线安装的是findBugs3.0的版本，这个版本对jdk的最低要求是jdk1.7。 P3C阿里插件 如上述步骤下载插件 使用方式和FindBugs一样","link":"/2018/11/22/代码扫描工具/"},{"title":"java多线程锁机制","text":"一、什么是线程锁我的理解是：多个线程在使用共享资源时,需要将资源进行锁定，让线程依次有序的进行获取资源。这个将资源进行锁定的动作就是加锁。 二、锁的种类Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率.如下图所示: 三、锁的状态 无锁 定义：无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。 特点：修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。 偏向锁 定义：指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。 特点：当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 轻量级锁 定义：是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。 特点： 重量级锁 定义：升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 特点： 重量级锁是将除了拥有锁的线程以外的线程都阻塞。 四、死锁 什么是死锁 死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。是操作系统层面的一个错误，是进程死锁的简称，最早在 1965 年由 Dijkstra 在研究银行家算法时提出的，它是计算机操作系统乃至整个并发程序设计领域最难处理的问题之一。 怎么防止死锁 死锁的四个必要条件： 互斥条件：进程对所分配到的资源不允许其他进程进行访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源 请求和保持条件：进程获得一定的资源之后，又对其他资源发出请求，但是该资源可能被其他进程占有，此事请求阻塞，但又对自己获得的资源保持不放 不可剥夺条件：是指进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用完后自己释放 环路等待条件：是指进程发生死锁后，若干进程之间形成一种头尾相接的循环等待资源关系 这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之 一不满足，就不会发生死锁。 五、锁对比 可重入锁 VS 非可重入锁 可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。 独享锁 VS 共享锁 独享锁和共享锁同样是一种概念。我们先介绍一下具体的概念，然后通过ReentrantLock和ReentrantReadWriteLock的源码来介绍独享锁和共享锁。 独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。 共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。 原文链接：https://juejin.im/post/5bee576fe51d45710c6a51e0 友情链接：(大佬)SnoWalker’s Blog","link":"/2019/03/25/java多线程锁机制/"},{"title":"动态获取枚举值","text":"业务背景 依据不同的code获取不同的描述，所以需要查找了动态获取枚举的问题 枚举设计 12345678910111213141516171819202122232425public enum BizOptOrderTypeEnum { /**办理*/ CHECK_IN(0, \"办理\"), /**取消*/ CANCEL(1, \"取消\"), /**修改*/ UPDATE(2, \"修改\"); private Integer code; private String desc; BizOptOrderTypeEnum(Integer code, String desc) { this.code = code; this.desc = desc; } public Integer getCode() { return code; } public String getDesc() { return desc; } 动态获取枚举的方式 1234567long st = System.currentTimeMillis();int code= Enum.valueOf(BizOptOrderTypeEnum.class,\"CHECK_IN\").getCode();long ed=System.currentTimeMillis(); System.out.println(\"动态枚举获取参数为\"+code+\";耗时时间：\"+(ed-st)); int code1=BizOptOrderTypeEnum.CHECK_IN.getCode(); long sd=System.currentTimeMillis(); System.out.println(\"枚举获取参数为\"+code1+\";耗时时间：\"+(sd-ed)); 总结动态获取枚举的值需要预先知道有哪些key,设计的时候需要依据谋个固定的值获取到固定格式的KEY，如果没有这个key的话.会抛出异常：java.lang.IllegalArgumentException，需要注意.","link":"/2019/03/07/动态获取枚举值/"},{"title":"okHttp报SSLPeerUnverifiedException异常解决方案","text":"前言最近在项目使用了okHttp进行网络通信，记录在使用okHttp对https进行请求是抛出SSLPeerUnverifiedException异常以及SSLHandshakeException异常问题的分析以及解决方式。 初始化OKHTTPClient客户端 请求参数的处理 12FormBody.Builder formBody = new FormBody.Builder();formBody.add(\"key\", value); url请求处理 12345Request request = new Request.Builder() .url(url) .addHeader(\"Content-Type\", \"application/x-www-form-urlencoded\") .post(formBody.build()) .build(); 返回结果的处理 123Call call = okHttpClient.newCall(request);Response response = call.execute();String bodyString = response.body().string(); SSLHandshakeException异常处理 此时直接发出https请求会返回以下错误 处理方法：对OKHTTPClient进行如下改造： 1234OkHttpClient okHttpClient = new OkHttpClient() .newBuilder() .sslSocketFactory(OkHttpsUtils.createSSLSocketFactory(), new TrustAllCerts()) .build(); 错误原因：其中sslSocketFactory传入了2个参数，进行本地证书的初始化赋值的动作，对于Https请求需要对本地证书进行初始化。 以下是createSSLSocketFactory源码以及TrustAllCerts源码 OkHttpsUtils.createSSLSocketFactory()： 12345678910111213public class OkHttpsUtils { public static SSLSocketFactory createSSLSocketFactory() { SSLSocketFactory ssfFactory = null; try { SSLContext sc = SSLContext.getInstance(\"TLS\"); sc.init(null,new TrustManager[]{new TrustAllCerts()}, new SecureRandom()); ssfFactory = sc.getSocketFactory(); }catch (Exception e){ e.printStackTrace(); } return ssfFactory; } } TrustAllCerts源码 12345678910111213141516public class TrustAllCerts implements X509TrustManager {@Overridepublic void checkClientTrusted(X509Certificate[] x509Certificates, String s) throws CertificateException {}@Overridepublic void checkServerTrusted(X509Certificate[] x509Certificates, String s) throws CertificateException {}@Overridepublic X509Certificate[] getAcceptedIssuers() { return new X509Certificate[0];}} SSLPeerUnverifiedException异常处理 经过上述步骤后,继续请求会出现如下错误： 解决方法:对OKHTTPClient进行如下改造： 12345OkHttpClient okHttpClient = new OkHttpClient() .newBuilder() .sslSocketFactory(OkHttpsUtils.createSSLSocketFactory(), new TrustAllCerts()) .hostnameVerifier(new TrustAllHostnameVerifier()) .build(); 错误原因：验证对方的证书不通过 TrustAllHostnameVerifier源码 123456public class TrustAllHostnameVerifier implements HostnameVerifier { @Override public boolean verify(String s, SSLSession sslSession) { return true; }} 以上的方式是直接不验证对方的证书。具体okHttps内容可以参考这个文章https://blog.csdn.net/lmj623565791/article/details/48129405 友情链接：(大佬)SnoWalker’s Blog","link":"/2019/03/13/okHttp报SSLPeerUnverifiedException异常解决方案/"},{"title":"单点登录原理与简单实现","text":"一、单系统登录机制1.http无状态协议传统的web应用采用B/S结构,采用http或者https进行通信。服务器端会独立处理每次浏览器发送的请求，每次请求之间互不干涉。实际如下图： 2.会话机制因为上述http请求的无状态性，会导致服务端资源可以被任何用户或者任何请求进行访问。为防止用户需要重复验证，需要引用会话机制。在浏览器第一次请求服务端时，服务端会生成一个会话以及会话ID返回给浏览器，浏览器接受响应后会将这个ID存入到cookie中，后续每次请求服务器端都会依据这个ID去判断是否是同一个用户请求。如下图： 3.登录状态为了避免用户频繁的登录系统，服务端需要维持用户的登录状态，即在上述的所说的会话中添加一个状态来标记用户是否已经登录，如果已经登录且用户的属性合法的话，就可以直接去请求服务器端对应的资源。 二、分布式集群登录状态的维持1.为什么引入单点登录随着系统的增多,单体应用已无法满足我们的需求,如图所示的应用，每个模块都有自己的域名,此时怎么保证用户在一个应用内部登录以后，在其他域名一样可以使用。此时不可能让用户自己去每个应用内部进行登录注册，然后每个域名去维护自己的会话系统,因此需要引入一个应用用于登录认证。 2.单点登录 介绍：在多系统应用群中登录一个系统，便可在其他所有系统中得到授权而无需再次登录，包括单点登录与单点注销两部分。 单点登录的流程图如下: 流程解释如下: 用户访问用户系统的受保护资源，用户系统发现用户未登录，跳转至认证中心，并将自己的地址作为参数 认证中心发现用户未登录，将用户引导至登录页面 用户输入用户名密码提交登录申请 认证中心校验用户信息，创建用户与认证中心之间的会话，称为全局会话，同时创建授权令牌token 认证中心带着令牌跳转会最初的请求地址（用户系统） 用户系统拿到令牌，去认证中心校验令牌是否有效 认证中心校验令牌，返回有效，注册用户系统 用户系统使用该令牌创建与用户的会话，称为局部会话，返回受保护资源 用户访问订单系统的受保护资源 订单系统发现用户未登录，跳转至认证中心，并将自己的地址作为参数 认证中心发现用户已登录，跳转回订单系统的地址，并附上令牌 订单系统拿到令牌，去认证中心校验令牌是否有效 认证中心校验令牌，返回有效，注册订单系统 订单系统使用该令牌创建与用户的局部会话，返回受保护资源 用户登录成功之后，会与sso认证中心及各个子系统建立会话，用户与sso认证中心建立的会话称为全局会话，用户与各个子系统建立的会话称为局部会话，局部会话建立之后，用户访问子系统受保护资源将不再通过sso认证中心，全局会话与局部会话有如下约束关系 局部会话存在，全局会话一定存在 全局会话存在，局部会话不一定存在 全局会话销毁，局部会话必须销毁 2.单点注销 全局会话注销时,需要告知子系统注销会话。 注销过程可以使用HttpSessionListener 监听去做 token生成与验证 可以使用jwt 总结理解流程，还需要手动搭建才行。 纸上得来终觉浅,绝知此事要躬行。 github地址：https://github.com/SeekingPlumBlossoms/singlelogin.git 友情链接：(大佬)SnoWalker’s Blog","link":"/2019/04/08/单点登录原理与简单实现/"},{"title":"宾哥的技术之旅","text":"今天我宾哥就是要干翻在座的各位渣渣！ 一级标题二级标题三级标题 子曰：不搞个个人技术博客还能叫程序员？ 鲁迅说：子说的对我怎么斜了？ 我怎么黄了? @Component public class HbaseClient { @Bean public HbaseTemplate hbaseTemplate(@Value(&quot;${hbase.zookeeper.quorum}&quot;) String quorum, @Value(&quot;${hbase.zookeeper.port}&quot;) String port) { HbaseTemplate hbaseTemplate = new HbaseTemplate(); org.apache.hadoop.conf.Configuration conf = HBaseConfiguration.create(); conf.set(&quot;hbase.zookeeper.quorum&quot;, quorum); conf.set(&quot;hbase.zookeeper.port&quot;, port); hbaseTemplate.setConfiguration(conf); hbaseTemplate.setAutoFlush(true); return hbaseTemplate; } }","link":"/2018/06/05/宾哥的技术之旅/"},{"title":"基于环形队列的高效延迟消息实现","text":"序本文介绍一种方案是利用环形队列的性质来做定时以及延时相关任务的调度处理。 高效延时消息设计与实现核心组件 环形队列:创建一个周期的环形队列(数组);例如3600 任务集合:在每个环形队列上要执行的任务集合，Set ScheduledExecutorService：JDK自带线程池，可以调度一些命令在一段时间后执行，或者周期性的执行，本次使用的是周期1S执行一次，也就相当于环形队列的指针，标记环形队列已经转动到的位置。 当前环形队列下标:表示人物执行到环形队列的位置,达到周期后置位0，同时周期轮数+1 周期循环的轮数:周期T*轮数+当前环形队列的下标=延时的时间示例图执行过程第一步：利用ScheduledExecutorService启动一个timer，每隔1S，在上述的环形队列中移动一格，0-&gt;1-&gt;2···有个CurrentSlotIndex来标记下标的位置第二步：当有任务需要延时执行时，计算出延时的轮数以及对应的下标的位置，将Task放到对应下标的任务集合中第三步：当CurrentSlotIndex取到某个位置后，取出对应位置的任务列表，循环遍历任务列表，当Task中的任务轮数与当前轮数相等时，就执行此条任务达到延时的效果; 方案的优点 无需轮询，效率高 无重复执行，一个任务只执行一次 能精确到秒(控制timer的频率可以控制周期) 方案的缺点 任务无持久化,重启之后会丢失任务 存储任务依赖内存,集中式请求会造成oom 长周期的任务会一直存储,无法分割 其余延时消息实现 定时器轮询遍历数据库记录 JDK的DelayQueue JDK ScheduledExecutorService 时间轮（netty） 利用quartz等定时任务 Redis的ZSet实现 rabbitMq实现延时队列","link":"/2019/06/03/基于环形队列的高效延迟消息实现/"},{"title":"手写基于zookeeper的RPC调用框架","text":"","link":"/2019/04/22/手写基于zookeeper的RPC调用框架/"},{"title":"深入浅出redis","text":"一、缓存基础概念 二八定律 巴莱多定律（也叫二八定律）是19世纪末20世纪初意大利经济学家巴莱多发现的。他认为，在任何一组东西中，最重要的只占其中一小部分，约20%，其余80%尽管是多数，却是次要的，因此又称二八定律 热数据 Redis混合存储实例将所有的Key都认为是热数据，以少量的内存为代价保证所有Key的访问请求的性能是高效且一致的。而对于Value部分，在内存不足的情况下，实例本身会根据最近访问时间，访问频度，Value大小等维度选取出部分value作为冷数据后台异步存储到磁盘上直到内存小于制定阈值为止。 冷数据 当内存不足时的情况下，实例会按照最近访问时间，访问频度，value大小等维度计算出value的权重，将权重最低的value存储到磁盘上并从内存中删除。 缓存雪崩 当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力，造成数据库后端故障，从而引起应用服务器雪崩。 缓存穿透 缓存穿透，是指查询一个数据库一定不存在的数据。举例：查询出不存在的数据，如果不放入空数据，会导致一直查询数据库，给数据库造成压力。 缓存击穿 缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。 缓存预热 缓存预热就是系统上线后，提前将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！ 缓存更新 更新缓存的设计模式有四种：Cache aside, Read through, Write through, Write behind caching Cache aside 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从cache中取数据，取到后返回 更新：先把数据存到数据库中，成功后，再让缓存失效。 Read through Read Through 是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。 Write Through Write Through 在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作） Write Behind Caching Pattern 俗称write back，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的I/O操作飞快无比，因为异步（比如消息队列），write back还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。 缓存降级 当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。 二、redis简介reids介绍reids是一个可以用于数据库、缓存和消息中间件的开源内存数据存储的系统 redis常用数据类型 其中常见的数据结构类型有：String、List、Set、Hash、ZSet这5种redis工作模式 硬盘数据库工作模式 内存存储索引，数据库存储key 内存数据库工作模式 value全部存储在内存中HA（High Availability） Redis 内置了复制（Replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（Transactions） 和不同级别的磁盘持久化（Persistence），并通过 Redis哨兵（Sentinel）和自动分区（Cluster）提供高可用性（High Availability）。 三、Redis为什么这么快redis有多快Redis采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的QPS（每秒内查询次数） redis快的原因 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)； 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的； 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 使用多路I/O复用模型，非阻塞IO:这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； 四、为什么Redis是单线程 官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）。五、扩展1、单进程多线程模型：MySQL、Memcached、Oracle（Windows版本）； 2、多进程模型：Oracle（Linux版本）； 3、Nginx有两类进程，一类称为Master进程(相当于管理进程)，另一类称为Worker进程（实际工作进程）。启动方式有两种： （1）单进程启动：此时系统中仅有一个进程，该进程既充当Master进程的角色，也充当Worker进程的角色。 （2）多进程启动：此时系统有且仅有一个Master进程，至少有一个Worker进程工作。 （3）Master进程主要进行一些全局性的初始化工作和管理Worker的工作；事件处理是在Worker中进行的。 友情链接：(大佬)SnoWalker’s Blog","link":"/2019/03/25/深入浅出redis/"},{"title":"深入理解Java虚拟机笔记---JVM的运行模式","text":"概述JVM有两种运行模式Server与Client。两种模式的区别在于，Client模式启动速度较快，Server模式启动较慢；但是启动进入稳定期长期运行之后Server模式的程序运行速度比Client要快很多。这是因为Server模式启动的JVM采用的是重量级的虚拟机，对程序采用了更多的优化；而Client模式启动的JVM采用的是轻量级的虚拟机。所以Server启动慢，但稳定后速度比Client远远要快。 查看运行模式的方法Java -version 2种模式的区别最主要的差别在于：-Server模式启动时，速度较慢，但是一旦运行起来后，性能将会有很大的提升.原因是:当虚拟机运行在-client模式的时候,使用的是一个代号为C1的轻量级编译器, 而-server模式启动的虚拟机采用相对重量级,代号为C2的编译器. C2比C1编译器编译的相对彻底,服务起来之后,性能更高. 所以通常用于做服务器的时候我们用服务端模式，如果你的电脑只是运行一下java程序，就客户端模式就可以了。当然这些都是我们做程序优化程序才需要这些东西的，普通人并不关注这些专业的东西了。其实服务器模式即使编译更彻底，然后垃圾回收优化更好，这当然吃的内存要多点相对于客户端模式。","link":"/2019/06/06/深入理解Java虚拟机笔记-JVM的运行模式/"},{"title":"深入理解Java虚拟机笔记---class类文件魔数,版本,常量池","text":"1.魔数每个class文件的头4个字节称为魔数(Magic Number)，其值为：0xCAFEBABE，它的唯一作用是用于确定这个文件是否为一个能被虚拟机接受的class文件。使用魔数而不是扩展名来进行识别主要是基于安全的考虑，因为文件的扩展名可以随意地被改动。 2.版本号紧接着魔的4个字节存储的是class文件的版本号：第5和第6个字节是次版本号(Minor Version)，第7和第8个字节是主版本号(Major Version)。java的版本是从45开始的，JDK1.1之后的每个JDK大版本发布主版本号上加1(JDK1.0-1.1使用了45.0-45.3的版本号)，高版本的JDK能向下兼容以前版本的class文件，但不能运行以后版本的class文件，即使文件格式并未发生变化。JDK1.2对应主版本号为46，JDK1.3为47，依此类推。 3.常量池紧接着主次版本号之后的是常量池入口，常量池是class文件结构中与其它项目关联最多的数据类型，也是占用class文件空间最大的数据项目之一，同时它还是class文件中第一个出现的表类型数据项目。由于常量池中常量的数据是不固定的，所以在常量池的入口需要放置一荐u2类型的数据，代表常量池容量计算值(constant_pool_count)。与Java语言习惯不一样的是，这个容量计数是从1而不是0开始的。将第0项常量出来的目的是为了满足后面某些指向常量池的索引值的数据在特定情况下需要表达“不引用任何一个常量池项目”的意思。class文件结构中只有常量池的容量计数是从1开始，对于其它集合类型，包括接口索引集合，字段表集合，方法表集合的容量计算都是从0开始的。常量池中主要存放两大类常量：字面量(Literal)和符号引用(Symbolic References)。字面量比较接近于Java语言层面的常量概念，如文本字符串，被声明为final的常量值等。而符号引用则属性编译原理方面的概念，包含了下面三类常量： 类和接口的全限定名(Fully Qualified Name) 字段的名称和描述符(Descriptor) 方法的名称和描述符 常量池中的每一项常量都是一个表，共有11种结构各不相同的表结构数据，这11种表都有一个共同的特点，就是表开始的第一位是一个u1类型的标志位，代表当前这个常量属性哪种常量类型，11种常量类型具体含义如下：各常量项结构：","link":"/2019/06/10/深入理解Java虚拟机笔记-class类文件魔数-版本-常量池/"},{"title":"深入理解Java虚拟机笔记---class类文件结构概述","text":"class文件是一组以8位字节为基础单位的二进制流，各个数据项目严格紧凑地排列在class文件中，中间没有任何分隔符。当遇到需要占用8位字节以上的的数据项时，则会按照高位在前的方式侵害成若干个8位字节进行存储。 根据Java虚拟机规范的规定，class文件格式采用一种类似于C语言结构体的伪结构来存储，这种伪结构只有两种数据类型：无符号数和表。无符号数属于基于数据类型，以u1、u2、u4、u8来分别代码1个字节、2个字节、4个字节、8个字节的无符号数，无符号数可以用于描述数字、索引引用、数量值，或者按照UTF-8编码构成的字符串值。表是由多个符号数或其它表作为数据项构成的复合数据类型，所有表都习惯性地以“_info”结尾。表用于描述有层次关系的复合结构，整个class文件本质上就是一张表，它由如下数据项构成：无论是无符号数还是表，当需要描述同一类型但数量不定的多个数据时，经常会使用一个前置的容量计数器加若干个连续的数据项的形式，这时候称这一系列连续的某一类型的数据为某一类型的集合。","link":"/2019/06/10/深入理解Java虚拟机笔记-class类文件结构概述/"},{"title":"深入理解Java虚拟机笔记---内存分配与回收策略","text":"Java技术体系中的自动内存管理最终可以归结为自动化地解决了两个问题：给对象分配内存以及回收分配给对象的内存。对象的内存分配往大的方向上讲，就是在堆上分配，对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲(-XX:+UseTLAB,默认已开启)，将按线程优先在TLAB上分配。少数情况下也可能会直接分配在老年代中，分配的规则并不是百分之百固定的，其细节取决于当前使用的是哪一种垃圾收集器组合，还有虚拟机中与内存相关的参数设置。下面是几条主要的最普遍的内存分配规则： 1.对象优先在Eden分配大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC，如果GC后新生代存活的对象无法全部放入Survivor空间，则需要通过分配担保机制提前进入到老年代中，前提是老年代不能容纳所有存活对象，只能容纳部分。则未能进入到老年代的存活对象将继续分配在Eden中，如果Eden区也还未能容纳剩余的存储对象虚拟机将抛出OutOfMemoryError错误。虚拟机提供了-XX:+PrintGCDetails参数用于输出收集器的日志参数。 minor GC:指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕死的特性，所以MinorGC非常频繁，一般回收速度也比较快 FullGC：指发生在老年代的GC，出现了FullGC，经常会伴随至少一次minorGC。fullGc的速度会比minorGC慢10倍以上。 2.大对象直接进入老年代所谓大对象是指，需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串及数组。大对象对虚拟机的内存分配来说是一个坏消息，经常出现大对象容易导致内存还有不少空间就提前触发垃圾收集以获取足够的连续空间来“安置”它们。虚拟机担任了一个-XX:PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代中分配。这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存拷贝。 3.长期存活的对象将进入老年代虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能够识别哪些对象应当放在新生代，哪些对象应该放在老年代。为了做到这点，虚拟机给每个对象定义了一个对象年龄计数器。如果对象在Eden区出生并经过第一次Minor GC后仍然存活，并且能被Survivor区容纳的话，将被移到Survivor区中，并将对象年龄设置为1。对象在Survivor区中每熬过一次Minor GC，年龄就增加1岁。当它的年龄增加到一定程度(默认为15岁)，就会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数-XX:MaxTenuringThreshold来设置。 4.动态对象年龄判定为了更好的适应不同程序的内存状况，虚拟机并不总是要求对象年龄必须达到MaxTenuringThreshold才能晋升到老年氏，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，那么年龄大于或等于该年龄的对象就直接进行老年代，无须等到MaxTenuringThreshold中要求的年龄。 5.空间分配担保在发生Minor GC时，虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代剩余空间的大小，如果大于，则改为直拉进行一次Full GC。如果小于，则查看HandlePromotionFailure设置是否允许担保失败；如果允许，那只会进行Minor GC；如果不允许，则要改为进行一次Full GC。 新生代使用复制收集算法，但为了提高内存利用率，只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在Minor GC后仍然存活的情况时，最需要老年代进行分配担保，让Survivor空间无法容纳的对象直接进入老年代。 取平均值进行比较仍然是一种动态概率的手段，也就是说如果某次Minor GC存活的对象突增，远高于平均值的话，依然会导致担保失败(HandlePromotionFailure)。如果出现了HandlePromotionFailure，那只好在失败后重新发起一次Full GC。虽然担保失败时绕圈子是最大的，但是大部情况下还是会将HandlePromotionFailure开关打开，避免Full GC过于频繁。","link":"/2019/06/06/深入理解Java虚拟机笔记-内存分配与回收策略/"},{"title":"深入理解Java虚拟机笔记---判断对象是否存活","text":"堆中几乎存放着Java世界中所有的对象实例，垃圾收集器在对堆回收之前，第一件事情就是要确定这些对象哪些还“存活”着，哪些对象已经“死去”(即不可能再被任何途径使用的对象) 1.引用计数算法（Reference Counting）很多教科书判断对象是否存活的算法是这样的：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值加1；当引用失效时，计数器减1；任何时刻计数器都为0的对象就是不可能再被使用的。 客观的说，引用计数法的实现简单，判定效率也很高，在大部分情况下他都是一个不错的算法。但是，在Java虚拟机里面没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间的循环引用问题。 例如：在testGC()方法中，对象objA和objB都有字段instance，赋值令objA.instance=objB及objB.instance=objA，除此之外这两个对象再无任何引用，实际上这两个对象都已经不能再被访问，但是它们因为相互引用着对象方，异常它们的引用计数都不为0，于是引用计数算法无法通知GC收集器回收它们。 12345678910111213141516171819public class Main { public Object instance = null; private byte[] bigSize = new byte[2 * 1024 * 1024]; public static void main(String[] args) { Main objA = new Main(); Main objB = new Main(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; //假设在这里发生GC，那么objA与objB是否会被回收 System.gc(); }} 运行结果：1234567891011[GC (System.gc()) [PSYoungGen: 8029K-&gt;936K(76288K)] 8029K-&gt;944K(251392K), 0.0018740 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (System.gc()) [PSYoungGen: 936K-&gt;0K(76288K)] [ParOldGen: 8K-&gt;724K(175104K)] 944K-&gt;724K(251392K), [Metaspace: 3361K-&gt;3361K(1056768K)], 0.0067709 secs] [Times: user=0.09 sys=0.00, real=0.01 secs] Heap PSYoungGen total 76288K, used 1966K [0x000000076b400000, 0x0000000770900000, 0x00000007c0000000) eden space 65536K, 3% used [0x000000076b400000,0x000000076b5eba40,0x000000076f400000) from space 10752K, 0% used [0x000000076f400000,0x000000076f400000,0x000000076fe80000) to space 10752K, 0% used [0x000000076fe80000,0x000000076fe80000,0x0000000770900000) ParOldGen total 175104K, used 724K [0x00000006c1c00000, 0x00000006cc700000, 0x000000076b400000) object space 175104K, 0% used [0x00000006c1c00000,0x00000006c1cb51e0,0x00000006cc700000) Metaspace used 3400K, capacity 4496K, committed 4864K, reserved 1056768K class space used 370K, capacity 388K, committed 512K, reserved 1048576K 从运行结果中可以看出虚拟并没有因为这两个对象相互引用就不回收它们，这也证明虚拟并不是通过通过引用计数算法来判断对象是否存活的。大家可以看到对象进入了老年代，但是大家都知道，对象刚创建的时候是分配在新生代中的，要进入老年代默认年龄要到了15才行，但这里objA与objB却进入了老年代。这是因为Java堆区会动态增长，刚开始时堆区较小，对象进入老年代还有一规则，当Survior空间中同一代的对象大小之和超过Survior空间的一半时，对象将直接进行老年代。 2.可达性分析算法（Reachability Analysis）在主流的商用程序语音（JAVA，C#）的主流实现中，都是通过可达性分析在判断对象是否存活。这个算法的基本思路就是通过一系列名为”GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。 在Java语言里，可作为GC Roots对象的包括如下几种： 虚拟机栈(栈桢中的本地变量表)中的引用的对象 方法区中的类静态属性引用的对象 方法区中的常量引用的对象 本地方法栈中JNI的引用的对象","link":"/2019/06/05/深入理解Java虚拟机笔记-判断对象是否存活/"},{"title":"深入理解Java虚拟机笔记---内存区域","text":"Java虚拟机在执行Java程序过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域有自各的用途，以及创建及销毁时间，有的区域随着虚拟机进程的启动而存在，有些区域则是依赖用户线程的启动和结束而建立和销毁。根据《Java虚拟机规范(第2版)》规定，Java虚拟机管理的内存区域包括以下几个运行时数据区域，如下图: 1.程序计数器(Program Counter Register)程序计数器是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。 字节码解释器工作时就是通过改为这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的多线程是通过线程轮流切换CPU时间片的方式来实现的，所以在任何一个时刻，一个处理器(对于多核处理器来说是一个内核)只会行一条线程中的指令。因此为了线各切换后能够恢复到正确的执行位置，每条线程都需要一个独立的程序计数器，为线程所私有。 如果当前线程执行的是一个Java方法，这个计数器是下在执行的虚拟机字节码的地址；如果执行的是一个Native方法，这个计数器的值为空(UndefinedD)，计算器必须要能容纳方法的返回地址或者具体平台的本地指针。此区域是唯一一个在Java虚拟机器中没有规定任何OutOfMemoryError的区域。 2.Java虚拟机栈与程序计数器一样，Java虚拟机栈(Java Virtual Machine Stacks)也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型；每个方法被执行时都会在虚拟机栈中创建一个栈桢(Stack Frame)用于存储操作数栈、动态链接、局部变量表等信息。每一个方法从调用直至其执行完成的过程，就对应了一个栈桢在虚拟机栈中入栈与出栈的过程。 虚拟机规范中说明了，Java虚拟机栈可以被实现为固定大小，也可以实现为根据计算动态扩展与收缩。如果被实现为固定大小，那么它需要被独立创建。Java虚拟机实现可能被给程序员与用户提供控制Java虚拟机栈的初始大小，当然，如果是动态扩展与收缩的实现，还可以控制虚拟机栈的最大与最小大小。 虚拟机规范在这个区域规定了两种异常状况：如果线程请求栈深度超过虚拟机允许的深度，虚拟机将会抛出一个StackOverflowError错误；如果虚拟机栈可以动态扩展(当前大部分虚拟机都可以动态扩展，只不过Java虚拟机规范允许固定长度的虚拟机栈)，当扩展时无法申请到足够的内存或者在创建一条新的线程时没有足够的内存创建一个初始大小的虚拟机栈时，Java虚拟机将抛出OutOfMemoryError错误。 3.本地方法栈本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。在虚拟机规范中对本地方法栈使用的语言、使用方式与数据结构并没有强制的规定，因此具体的虚拟机可以自由的实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接把本地方法栈和虚拟机合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 4.java堆对于大多数应用来说，Java堆(Java Heap)是Java虚拟机所管理的内在中最大的一块。Java堆是被所有线程共享的一块内在区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。虚拟机规范中的描述是：所有类的实例与数组对象都要在堆中分配。 java堆是垃圾收集器管理的主要区域，因此很多时候也被称作“GC堆”（Garbage Collected Heap）。从内存回收的角度来看，由于现在收集器基本都采用分代手机算法，所以java堆中还可以细分为：新生代和老年代；在细致一点的有Eden空间、From Survivor空间、To Survivor空间等。从内存分配的角度来看，线程共享的java堆中可能划分出多个线程私有的分配缓冲区（Thread Local Allocation Beffer，TLAB）。不过无论如何划分，都与存放内容无关，无论哪个区域，存储的都任然是对象实例，进一步划分的目的是为了更好的回收内存，或者更快的分配内存。 根据Java虚拟机规范的规定，java堆可以处于物理上不连续的内存空间中，只要逻辑上连续的即可。既可以实现固定大小的，也可以是可扩展的，不过当前主流的虚拟就都是按照可扩展来实现的（通过-Xmx 和 -Xms控制）。如果堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfmemoryError异常。 5.方法区方法区（Method Area）和java堆一样，都是各个线程共享的区域，它用于存储已虚拟机加载的类信息、常量、静态常量、即时编译器编译后的代码等数据。 与Java堆一样，方法区不需要连续的内存和可以选择固定大小与可扩展收缩外，还可以选择不实现垃圾收集，因为方法区的垃圾收集效果不理想。当方法区无法满足内在分配要求时，将抛出OutOfMemory异常。 6.运行时常量池运行时常量池（Runtime Contant Pool）是方法区的一部分。class方法中除了有类的版本号、字段、方法、接口等描述信息，还有一项信息是常量表（Cantant Pool Table），用于存储编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。 运行时常量池相对于class文件常量池的一个重要特征就是具备动态性，Java语言并不要求常量一定只能在编译期产生，也就是并非预置入class方法中的常量池中的内容才能进入到方法区的运行时常量池，程序运行期间也可以将新的常量放入常量池中，例如String类的intern()方法。 运行时常量时是方法区的一部分，自然也会受到方法区内存大小的限制，当常量池无法再申请到内存时会抛出OutOfMemory异常。 7.直接内存直接内存(Direct Memory)并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError错误出现。垃圾进行收集时，虚拟机虽然会对直接内存进行回收，但却不能像新生代与老年代那样，发现空间不足了就通知收集器进行垃圾回收，它只能等到老年代满了后FullGC时，然后”顺便”清理掉直接内存中废弃的对象。 在JDK1.4中新加入了NIO，引入了一种基于通道(Channel)与缓冲区(Buffer)的I/O方法，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。","link":"/2019/06/05/深入理解Java虚拟机笔记-内存区域/"},{"title":"深入理解Java虚拟机笔记---垃圾收集算法","text":"当对象判定为”已死”状态，虚拟就要采取一定的手段将这些对象从内存中移除，即回收垃圾，回收过程有采用一定的算法。如下是一些主要的垃圾收集算法： 1.标记-清除算法（Mark-Sweep）最基础的算法收集算法是”标记-清除”算法，如同它的名字一样，算法分为“标记”和“清除”2个阶段：首先标记处所有需要回收的对象，在标记完成后统一回收所有被标记的对象。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。它的主要不足有2个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。标记-清除算法的执行过程如下： 2.复制算法为了解决效率问题，一种称为“复制”的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配是也就不用考虑内存碎片等复杂的情况，只要移动指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半，未免太高了点。复制算法如下：现在的商业虚拟机都采用这种收集算法来回收新生代，IBM公司的专门研究表明，新生代中的对象98%是“朝生夕死”的，所以不需要按照1:1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性复制到另外一块的Survivor空间上，最后清零掉Eden和刚才使用的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8：1，也就是每次新生代中可用的内存为整个新生代容量的90%（80%+10%）,只有10%的内存会被“浪费”。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。 3.标记-整理算法复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。 根据老年代的特点，有人提出了另外一种“标记-整理”算法，标记过程仍然和“标记-清除”算法一样，但是后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存，“标记-整理”算法的示意图如下： 4.分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”(Generational Collection)算法，该算法将根据对象存活周期不同将内存划分为几块。一般把Java堆分为新生代与老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集都发现有大量对象死去，只有少量对象存活，就选得复制收集算法，只要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外的空间对其进行分配担保，就必须使用“标记-清除”或“标记-整理”算法进行回收。","link":"/2019/06/06/深入理解Java虚拟机笔记-垃圾收集算法/"},{"title":"深入理解Java虚拟机笔记---垃圾收集器","text":"如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。Java虚拟机规范中对象垃圾收集器应该如何实现并没有任何规定，因此不同的厂商，不同版本的虚拟机所提供的收集器可能会有很的差别，并且一般会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的收集器。下面是Sun HotSpot虚拟机1.6版本Update22包含的所有收集器： 上图中，如果两个收集器之间存在连线，就说明它们可以搭配使用。 1.Serial收集器Serial收集器是最基本、历史最悠久的收集器，曾经(在JDK1.3.1之前)是虚拟机新生代的唯一选择。这是一个单线程的收集器，但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾工作，更重要的是它进行垃圾回收都，必须暂停其它所有工作线程(Sun将这件事情称之为“Stop The World”)，直到它收集结束。下面是Serial/Serial Old收集器的运行过程： 到目前为止，Serial收集中是虚拟机运行在Client模式下的默认重新代收集器。它简单而高效(与其它收集器的单线程相比)，对于限定单个CPU环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。在桌面应用场景中，分配给虚拟机的内存一般来说不会太大，收集几直兆甚至一两百兆的新生代，停顿时间完全可以控制在几十毫秒最多一百多毫秒内，只要不是频繁发生，这点停顿是可以接受的。所以，Serial收集器对于运行在Client模式下的虚拟机来说是一个很好的选择。 2.ParNew收集器ParNew收集器是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包含Serial收集器可用的所有控制参数(例如:-XX:SurvivorRatio、-XX:PretenureSizeThreshold、-XX:HandlePromotionFailure等)、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样。ParNew收集器的工作过程如下图： 3.Parallel Scavenge收集器Parallel Scavenge收集器也是一个新生代收集器，它也是使用复制收集算法。其特点是与其它收集器的关注点不同，CMS等收集器关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目的是达到一个可控制的吞吐量(Throughput)。所以吞量就是CPU用于运行用户代码的时候与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收回时间)。停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户的体验；而高吞吐量可以最高次第的利用CPU时间，尽快的完成程序任务，主要适合在后台运算而不需要太多交互的任务。Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis及直接设置吞吐量大小的-XX:GCTimeRatio。Parallel Scavenge收集器还有一个参数-XX:UseAdaptiveSizePolicy，这是一个开关参数，当这个参数打开之后，就不需要手工指定新生代大小、Eden与Survivor区的比例，晋升老年代对象年龄等细节参数了。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调用事这些参数以提供最合适的停顿时间或最大的吞吐量，这种调节方式称为GC自适应调用策略(GC Ergonomics)。 4.Serial Old收集器Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用”标记-整理“算法。这个收集器的主要意义也是被client模式下的虚拟机使用。如果在server模式下，它主要有两大用途：一个是在JDK1.5及之前的版本中与Parallel Scavenge收集器搭配使用，另外一个就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure的时候使用。Serial Old收集器的工作过程如下图： 5.Parallel Old收集器Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和”标记-整理“算法。这个收集器是在JDK1.6中才开始提供的，在此之前，新生代的Parallel Scavenge收集器一直处于比较尴尬的状态。原因是如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old(PS MarkSweep)收集器之外别无选择。Parallel Old收集器的工作过程如下图： 6.CMS收集器CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中中互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，CMS收集器就非常符合这应用的需求。CMS收集器是基于”标记-清除“算法实现的，它的运作过程相对前面几种收集器来说要复杂一点，整个过程分为4个步骤，包括： 初始标记(CMS initial mark) 并发标记(CMS concurrent mark) 重新标记(CMS remark) 并发清除(CMS concurrent sweep) 其中初始标记、重新标记这两个步骤仍然需要”Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间，因为用程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 由于整个过程上耗时最长的并发标记与并发清除过程中，收集器线程可以与用户线程一起工作，所以总体上说，CMS收集器的内存回收过程是与用户线程一起并发地执行的。执行图如下： CMS是一款优秀的收集器，但它有三个显著缺点： CMS收集器对CPU资源非常敏感。 CMS收集器无法处理浮动垃圾(Floating Garbage)，可能出现”Concurrent Mode Failure”失败而导致另一次Full GC的产生。 CMS收集器采用“标记-清除”算法，这样会导致出现大量内存碎片。 7.G1收集器G1收集器是垃圾收集器理论进一步发展的产物，它与前面的CMS收集器相比有两个显著改进：一是G1收集器是基于“标记-整理”算法实现，也就是说它不会产生内存碎片，这对于长时间运行的应用系统来说非常重要。二是它可以非常精确地控制停顿，即能让使用都明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不超过N毫秒，这几乎已经是实时Java(RTSJ)的垃圾收集器的特征了。G1收集器可以实现在基本不牺牲吞量的前提下完成低停顿的内存回收，这是由于它能够极力地避免全区域的垃圾收集，之前的收集器进行收集的范围都是整个新生代或老年代，而G1将Java堆(包含新生代与老年代)划分为多个大小固定的独立区域，并且跟踪这些区域里的垃圾堆积程度，在后台维护一个优先列表，每次根据允许的收集时间，优先回收垃圾最多的区域(这就是Garbage First名称的由来)。区域划分及优先级的区域回收，保证了G1收集器在有限时间内可以获得最高的收集效率。","link":"/2019/06/06/深入理解Java虚拟机笔记-垃圾收集器/"},{"title":"深入理解Java虚拟机笔记---字段表集合","text":"字段表(field_info)用于描述接口或类中声明的变量。字段(field)包括了类级变量或实例变量，但不包括方法内部声明的变量。描述一个字段的信息有：字段的作用域(public,private,protected修饰符)，是类级变量还是实例级变量(static修饰符)，可变性(final)，并发可见性(volatile修饰符，是否强制从主内存读写)，是否可序列化(transient修饰符)，字段数据类型(基本数据类型，对象，数组)，字段名称。这些信息中，各个修改符都是布尔值，要么有某个修饰符，要么没有，很适合使用标志位来表示。而字段叫什么名字，字段被定义为什么数据类型，这些都是无法固定的，只能引用常量池中的常量来描述。下面是字段表的最终格式。 字段修饰符放在access_flags项目中，它与类的access_flags项目是非常相似的，都是一个u2的数据类型，其中可以设置的标志位和含义如下表：跟随access_flags标志的是两项索引值：name_index和descriptor_index。它们都是对常量池的引用，分别代表着字段的简单名称及字段的描述符。现在需要解释一下“简单名称”，“描述符”及前面出现过多次的“全限定名”这三种特殊字符串的概念。全限制名称和简单名称很好理解，如“org/fenixsoft/clazz/TestClass”就是一个类全限制名，仅仅是把类名中的”.“替换成了”/“而已，为了使连续的多个全限定名之间不产生混淆，在使用时最后一般会加上一个“;”号表示全限定名结束。简单名称就是指没有类型和参数修饰的方法或字段名称。相对于全限定名和简单名称来说，方法和字段的描述符就要复杂一些。描述符的作用是来用描述字段的数据类型，方法的参数列表(包括数量，类型及顺序)和返回值。根据描述符规则，基本数据类型(byte,char,double,float,int,long,short,boolean)及代表无返回值的void类型都使用一个大写字符来表示，而对象类型则用字符L加对象全限定名来表示，如下图：对于数组类型，每一维度使用一个前置的 字符来描述，如一定义为java.lang.String[][]类型的二维数组，将被记录为：“[[java/lang/String;”，一个整型数组“int[]”将被记录为“[I”。用描述符来描述方法时，按照先参数列表，后返回值的顺序描述，参数列表按照参数的严格顺序在一组小括号“()”之内。如方法void int()描述符为：”()V“，方法java.lang.String toString()描述符为：“()java/lang/String;”字段表都包含的固定数据项目到descriptor_index为止就结束了，但是在descriptor_index之后跟随着一个属性表集合用于存储一些额外的信息，字段都可以在属性表中描述0至多项额外的信息。字段表集合中不会列出超类或父接口中继承而来的字段，但有可能列表出原来Java代码中不存在的字段，譬如在内部类中为了保持对外部类的访问性，会自动添加指向外部类实例的字段。另外，在Java语言中字段是无法重载的，两个字段的数据类型，修饰符不管是否相同，都必须使用不一样的名称，但是对于字段码来讲，如果两个字段的描述符不一致，那字段重名就是合法的。","link":"/2019/06/10/深入理解Java虚拟机笔记-字段表集合/"},{"title":"深入理解Java虚拟机笔记---方法表集合","text":"方法表的结构与字段表一样，依次包含了访问标志(access_flags)，名称索引(name_index)，描述符索引(descriptor_index)，属性表集合(attributes)几项，如下表所示：因为volatile关键字和transient关键字不能修改方法，所以方法表的访问标志中没有了ACC_VOLATILE与ACC_TRANSIENT标志。与之相对的，synchronized, native, strictfp和abstract关键字可以修饰方法，所以方法表的访问标志中增加了ACC_SYNCHRONIZED，ACC_NATIVE，ACC_STRICTFP，ACC_ABSTRACT标志。对于方法表，所有标志位及取值如下表：方法里面的Java代码，经过编译器编译成字节码指令后，存放在方法属性表集合中一个名为“Cocde”的属性表中，属性表是class文件桥口中最具扩展性的一种数据项目。 与字段表集合相对应的，如果父类方法在子类中没有被重写(Override)，方法表集合中就不会出现父类的方法。但同样的，可能会出现由编译器自动添加的方法，最典型的便是类构造器“”方法和缺省实例构造器“”方法。在Java语言中，要重(Override)一个方法，除了要与原方法具有相同的简单名称之外，还要求必须拥有一个与原方法不同的特征签名，特征签名是一个方法中各个参数在常量池中的字段符号引用的集合，也就是因为返回值不会包在特征签名之中，因为Java语言里是无法仅仅依靠返回值的不同来对一个已有的方法进行重载的。但在Class文件格式中，特征签名的范围更大一些，只要描述符不是完全一致的两个方法就可以共存。也就是说，如果两个方法有相同的名称和特征签名，但返回值不同，那么也是可以合法共存于同一个class文件中。","link":"/2019/06/10/深入理解Java虚拟机笔记-方法表集合/"},{"title":"深入理解Java虚拟机笔记---理解GC日志","text":"阅读GC日志是处理JAVA虚拟机内存问题的基础技能，他只是一些人为确定的规则，没有太多的技术含量。但是不能说它不重要。。。 1.GC日志举例：12[GC (System.gc()) [PSYoungGen: 8029K-&gt;840K(76288K)] 8029K-&gt;848K(251392K), 0.0009744 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (System.gc()) [PSYoungGen: 840K-&gt;0K(76288K)] [ParOldGen: 8K-&gt;705K(175104K)] 848K-&gt;705K(251392K), [Metaspace: 3401K-&gt;3401K(1056768K)], 0.0052885 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] PSYoungGen:表示的使用的Parallel Scavenge收集器； “[GC” 与 ”[Full GC“表示了这次垃圾收集的停顿的类型，而不是用来区分新生代GC还是老年代GC的。 8029K-&gt;840K(76288K):GC前该内存区域已使用容量-&gt;GC后该内存区域已使用容量(该内存区域总容量) 8029K-&gt;848K(251392K)：java堆的数据 0.0009744 secs：表示GC的时间 [Times: user=0.02 sys=0.00, real=0.01 secs]：这里面的user，sys和real与LInux的time命令所输出的时间含义一致，分别代表用户态消耗的CPU时间、内核态消耗CPU时间和操作从开始到结束所经过的墙钟时间。CPU时间和墙钟时间的区别是。墙钟时间包括各种非运算的等待耗时，例如等待磁盘IO，等待线程阻塞，而CPU时间不包括这些耗时，但当系统有多CPU或者多核的话，多线程操作会叠加这些CPU时间，所以有时会看到user或sys时间超过real时间是完全正常的。 2.垃圾收集器参数总结 参数 描述 UseSerialGC 虚拟机运行在Client模式下的默认值，打开此开关后，使用Serial+serial Old的收集器组合进行内存回收 UseParNewGC 打开此开关后，使用ParNew+Serial Old的收集器组合进行内存回收 UseConcMarkSweepGC 打开此开关后，使用ParNew + CMS + Serial Old的收集器组合进行内存回收。Serial Old收集器将作为CMS收集器出现Concurrent Mode Failure失败后的后备收集器使用。 UseParallelGC 虚拟机运行在Server模式下的默认值，打开此开关后，使用Parallel Scavenge + Serial Old的收集器组合进行内存回收 UseParallelOldGC 打开此开关后，使用Parallel Scavenge + ParallelOld的收集器组合进行内存回收 SurvivorRation 新生代中Eden区域与Survivor区域的容量比值，默认为8，代表Eden：Survivor=8:1 MaxTenuringThreshold 晋升到老年代的对象年龄。每个对象在坚持过一次Minor GC之后，年龄就增加1，当超过这个参数值时就进入老年代。 UseAdaptiveSizePolicy 动态调整Java堆中各个区域的大小以及进入老年代的年龄 HandlePromotionFailure 是否允许分配担保失败，即老年代的剩余空间不足以应付新生代的整个Eden和Survivor区的所有对象都存活的极端情况 ParallelGCThreads 设置并行GC时进行内存回收的线程数 GCTimeRatio GC时间占总时间的比率，默认值为99，即允许1%的GC时间。仅在使用Parallel Scavenge收集器时生效 MaxGCPauseMillis 设置GC的最大停顿时间。仅在使用Parallel Scavenge收集器时生效 CMSInitiatingOccupancyFraction 设置CMS收集器在老年代空间被使用多少后触发垃圾收集。默认值为68%，仅在使用CMS收集器时生效 UseCMSCompactAtFullCollection 设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片整理。仅在使用CMS收集器时生效 CMSFullGCsBeforeCompaction 设置CMS收集器在进行若干次垃圾收集后再启动一次内存碎片整理。仅在使用CMS收集器时生效 UseCMSInitiatingOccupancyOnly 我们用-XX+UseCMSInitiatingOccupancyOnly标志来命令JVM不基于运行时收集的数据来启动CMS垃圾收集周期。而是，当该标志被开启时，JVM通过CMSInitiatingOccupancyFraction的值进行每一次CMS收集，而不仅仅是第一次。然而，请记住大多数情况下，JVM比我们自己能作出更好的垃圾收集决策。因此，只有当我们充足的理由(比如测试)并且对应用程序产生的对象的生命周期有深刻的认知时，才应该使用该标志。","link":"/2019/06/06/深入理解Java虚拟机笔记-理解GC日志/"},{"title":"設計模式之單例模式","text":"单例模式介绍单例模式（Single Pattern）:确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。 单例模式的应用1.单例模式的优点 由于单例模式在内存中只有一个实例，减少了内存开支，特别是一个对象需要频繁的创建、销毁时,而且创建或者销毁时性能又无法优化,单例模式的优势就非常明显。 由于单例模式只生成一个实例，所以减少了系统的性能开销，当一个对象的产生需要 比较多的资源时,如读取配置，产生其他依赖对象时，则可以通过在应用启动时直接产生一个单例对象,然后用永久驻留内存的方式来解决(在java EE中采用单例模式时需要注意JVM垃圾回收机制)。 单例模式可以避免对资源的多重占用,例如一个写文件的动作,由于只有一个实例存在内存中，避免对同一个资源文件的同时写操作。 单例模式可以再系统设置全局的访问点，优化和共享资源访问，例如可以设计一个单例类，负责所有数据表的映射处理。 2.单例模式的缺点 单例模式一般没有接口,扩展很困难,若要扩展,除了修改代码基本上没有第二种途径可以实现。因为接口对单例模式是没有任何意义的，它要求”自行实例化”，并且提供单一实例、接口或抽象类是不可能被实例化的。当然，在特殊情况下，单例模式可以实现接口、被继承等，需要在系统开发中根据环境判断。 单例模式对测试是不利的。在并发开发环境中，如果单例模式没有完成，是不能进行测试的，没有接口也不能使用mock的方式虚拟一个对象。 单例模式与单一职责原则有冲突。一个类应该只实现一个逻辑，而不关心它是否是单例的，是不是要单例取决于环境，单例模式把“要单例”和业务逻辑融合在一个类中。 3.单例模式的使用场景 要求生成唯一序列号的环境； 在整个项目中需要一个共享访问点或者共享数据，例如一个web页面上的计数器，可以不用把每次舒心都记录到数据库中，使用单例模式保持计数器的值，并确保是线程安全的； 创建一个对象需要消耗的资源过多，如要访问IO和数据库等资源; 需要定义大量的静态资源和静态方法(如工具类)的环境，可以采用单例模式（当然，也可以直接声明为static的方式） github示例:单例模式 友情链接：(大佬)SnoWalker’s Blog","link":"/2018/12/04/設計模式之01單例模式/"},{"title":"深入理解Java虚拟机笔记---类索引-父类索引-接口索引集合","text":"类索引(this_class)和父类索引(super_class)都是u2类型的数据，而接口索引(interfaces)是一组u2类型的数据集合，class文件中由这三项数据来确定这个类的继承关系。类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名。由于Java语言不允许多继承，所以父类索引只有一个，除了java.lang.Object之外，所有的Java类都有父类，因了除了java.lang.Object之外，所有Java类的父类索引都不为0。接口索引集合用来描述这个实现实现了哪些接口，这些被实现的接口将按照implements语句后的接口顺序从左到右排列在接口的索引集合中。 类索引，父类索引和接口索引集合都按顺序排列在访问标志之后，类索引和父类索引用两个u2类型的索引值表示，它们各自指向一个类型为CONSTANT_Class_info的类描述符常量，通过CONSTANT_Class_info类型的常量中的索引可以找到定义在CONSTANT_Utf8_info类型的常量中的全限定名称字符串。对于接口索引集合，入口的第一项为u2类型的数据，表示接口计数器(interfaces_countD)，表示索引表的容量。如果该类没有实现任何接口，那么该计数器值为0，后面接口的索引表不再占用任何字节。","link":"/2019/06/10/深入理解Java虚拟机笔记-类索引-父类索引-接口索引集合/"},{"title":"深入理解Java虚拟机笔记---访问标志","text":"常量池结束之后，紧接着的2个字节代表访问标志(access_flags)，这个标志用于识别一些或接口层次的访问信息，包括：这个class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类的话，是否被声明为final，等等。具体的标志五个一标志的含义如下表：access_flags中一共有32个标志位可以使用，当前只定义了其中的8个，没有使用到的标志位要求一律为0。","link":"/2019/06/10/深入理解Java虚拟机笔记-访问标志/"},{"title":"設計模式之中介者模式","text":"中介者模式介绍 定义 中介者模式:用一个中介对象封装一系列的对象交互，中介者使个对象不需要显示地互相交互，从而使其耦合松散，而且可以独立地改变它们之间的交互。 Mediator抽象中介者角色 抽象中介者角色定义统一的接口，用于各角色之间的通信。 ConcreteMediator具体中介者角色 具体中介者角色通过协调各同事角色实现协作行为，因此它必须依赖于各个同事角色。 Colleague同事角色 每一个同事角色都知道中介者角色，而且与其他的同事角色的通信的时候，一定要通过中介者角色协作。每个同事类的行为分为2种：一种是同事本身的行为，比如改变对象本身的状态，处理自己的行为等。这种行为叫做自发行为(Self-Method),与其他的同事类或者中介者没有任何的依赖；第二种是必须依赖中介者才能完成的任务的行为，叫做依赖方法。 中介者模式的应用1.中介者模式的优点 中介者模式的优点就是减少类间的依赖，把原有的一对多的依赖变成了一对一的依赖，同事类只依赖中介者，减少了依赖，当然同事也降低了类间的耦合。 2.中介者模式的缺点 中介者模式的缺点就是中介者会膨胀得很大，而且逻辑复杂，原本N个对象直接的相互依赖关系转换为中介者和同事类的依赖关系，同事类越多，中介者的逻辑就越多。 3.中介者模式的使用场景 N个对象之间产生了相互依赖的关系(N&gt;2)。 多个对象有依赖关系，但是依赖的行为尚不能确定或者发生改变的可能，在这种情况下一般建议采用中介者模式，降低变更引起的风险扩散。 产品开发。把中介者模式应用到产品中，可以提升产品的性能和扩展性，但是对于项目开发就未必，因为项目是以交付投产为目标，而产品则是以稳定、高效、扩展为宗旨。 4.中介者模式案例 MVC框架 MVC框架：其中的C(Controller)就是一个中介者，叫做前端控制器，它的作用就是把M(Model，业务逻辑)和V(View,视图)隔离开，协调M和V协调工作，把M的运行结果和V代表的视图融合成一个前端可以展示的页面，减少M和V的依赖。 中介服务 媒体网关 机场调度中心 github示例:单例模式 友情链接：(大佬)SnoWalker’s Blog","link":"/2018/12/05/設計模式之中介者模式/"},{"title":"設計模式之代理模式","text":"代理模式介绍 代理模式定义 代理模式(ProxyPattern):为其他对象提供一种代理以控制对这个对象的访问。 Subject抽象主体角色 抽象主题类可以是抽象类也可以是接口，是一个最普通的业务类型定义，无特殊要求。 RealSubkect具体主题角色 也叫做被委托的角色、被代理角色。它才是冤大头，是业务逻辑的具体执行者。 Proxy代理主题角色 *也叫做委托类、代理类。它负责对真实角色的应用，把所有抽象主题类定义的方法限制委托给真实的主题角色实现，并且在真实主题角色处理完毕前后做预处理和善后处理工作。 代理模式的应用1.代理模式的优点 职责清晰 真实的角色就是实现实际的业务逻辑，不用关心其他非本职责的事务，通过后去的代理完成一件事务，附带的结果就是编程简洁清晰。 高扩展性 具体主题角色是随时都会发生变化的，只要它实现了接口，甭管它如何变化，都逃不脱如来佛的手掌(接口)，那我们的代理类完全就可以再不做任何修改的情况下使用。 智能化 2.代理模式的扩展 普通代理 强制代理 动态代理 github示例:代理模式 友情链接：(大佬)SnoWalker’s Blog","link":"/2018/12/05/設計模式之代理模式/"},{"title":"設計模式之原型模式","text":"原型模式介绍 原型模式的定义 原型模式(PrototypePattern):用原型实例指定创建对象的种类，并且通过考呗这些原型创建新的对象。 原型模式的应用1.原型模式的优点 性能优良 原型模式是在内存二进制流的拷贝，要比直接new一个对象性能要好很多，特别是在一个循环体内产生大量的对象时，原型模式可以更好地体现其优点。 逃避构造函数的约束 这既是他的优点也是他的缺点，直接在内存中拷贝，构造函数不会被执行。优点就是减少了约束。 2.原型模式的使用场景 资源优化场景 类初始化需要消化非常多的资源，这个资源包括数据，硬件资源等。 性能和安全要求的场景 通过new产生一个对象需要非常繁琐的数据准备或者访问权限，则可以使用原型模式。 一个对象多个修改者的场景 一个对象需要提供给其他对象访问，而且各个调用者都可能需要修改其值时，可以考虑使用原型模式拷贝多个对象供调用者使用。 3.原型模式注意事项 构造函数不会被执行 浅拷贝和深拷贝 clone和final冲突 github示例: 原型模式 友情链接：(大佬)SnoWalker’s Blog","link":"/2018/12/05/設計模式之原型模式/"},{"title":"設計模式之建造者模式","text":"建造者模式介绍 定义 建造者模式(BuilderPattern):将一个复杂对象的构建与他的表示分离，使得同样的构建过程可以创建不同的表示。 Product产品类： 通常是为了实现模板方法模式，也就是有模板方法的基本方法。 Builder抽象建造者 规范产品的组建，一般是由子类实现。 ConcreteBuilder具体建造者 实现抽象类定义的所有方法，并且返回一个组建好的对象。 Director导演类 负责安排已有的模块的顺序，然后告诉Builder开始建造。 建造者模式的应用建造者模式的优点 封装性 使用建造者模式可以使客户端不必知道产品内部的组成细节。 建造者独立，容易扩展 便于控制细节风险 由于具体的建造者是独立的，因此可以对建造过程逐步细化，而不对其他的模板产生任何的影响。 建造者模式的使用场景 相同的方法，不同的执行顺序，产生不同的事件结果时，可以采用建造者模式。 多个部件或者零件，都可以装配到一个对象中，但是产生的运行结果又不相同时，则可以使用该模式。 产品类非常复杂，或者产品类中的调用顺序不同产生了不同的效能，这个时候使用建造者模式非常合适。 在对象创建过程中会使用到系统中的一些其他对象，这些对象在产品对象的创建过程中不易得到时，也可以采用建造者模式封装对该对象的创建过程，这种场景只能是一个补偿方法，因为一个对象不容易获得，而在设计阶段竟然没有发觉，而要通过创建者模式柔化创建过程，本身已经违反涉及的最初目标。 github示例:建造者模式 友情链接：(大佬)SnoWalker’s Blog","link":"/2018/12/05/設計模式之建造者模式/"},{"title":"設計模式之工厂方法模式","text":"工厂方法模式介绍工厂方法模式：定义一个用于创建对象的接口，让子类决定实例化哪一个类。工厂方法使一个类的实例化延迟到其子类。 工厂方法模式应用工厂方法模式的优点 良好的封装性，代码结构清晰。 工厂模式的扩展性非常优秀。在增加产品类的情况下，只要适当的修改具体的工厂类或者扩展一个工厂类就可以完成”拥抱变化”。 屏蔽产品类。这一特点非常重要，产品类的实现如何变化，调用者都不需要关心，它只需要关心产品的接口，只要接口保持不变，系统的上层模块就不要发生变化，因为产品类的实例化工作是由工厂类负责的，一个产品对象具体由哪一个产品生产是由工厂类决定的。 工厂方法模式是典型的解耦框架。高层模块只需要知道产品的抽象类，其他的实现类都不用关心，符合迪米特法则，我不需要的就不要去交流，也符合依赖倒置原则，只依赖产品类的抽象，当然也符合里式替换原则，使用产品子类替换产品父类，没有问题！ 工厂方法模式的使用场景 工厂方法模式是new一个对象的替代品，所以在所有需要生成对象的地方都可以使用，但是需要慎重的考虑是否需要增加一个工厂类进行管理，增加代码的复杂度。 需要灵活的、可扩展的框架时，可以考虑工厂模式。 工厂方法模式可以用在异构项目中，例如通过webservice与一个非Java的项目交互，虽然webservice号称是可以做到异构系统的同步化，但是在实际的开发中，还是会碰到很多问题，如类型问题、WSDL文件的支持问题，等等。 可以使用在测试驱动开发的框架下。例如，测试一个类A，就需要把与类A有关联关系的类B也同时产生出来，我们可以使用工厂方法模式把类B虚拟出来，避免类A与类B的耦合。目前由于JMock和EasyMock的诞生，该使用场景已经弱化了。 github示例:工厂方法模式 友情链接：(大佬)SnoWalker’s Blog","link":"/2018/12/04/設計模式之工厂方法模式/"},{"title":"設計模式之抽象工厂模式","text":"抽象工厂模式介绍抽象工厂模式(Abstract Factory Pattern):为创建一组相关或相互依赖的对象提供一个接口，而且无需指定它们的具体类。 抽象工厂模式的应用1.抽象工厂模式的优点 封装性，每个产品的实现类不是高层模块要关心的，它要关心的是什么？是接口，是抽象，它不关心对象是如何创建出来，这由谁负责呢？工厂类，只要知道工厂类是谁，我就能创建出一个需要的对象，省时省力，优秀设计就应该如此。 产品族内的约束为非公开状态。具体的产品族内的约束是在工厂内实现的。 2.抽象工厂模式的缺点 抽象工厂模式的最大缺点就是产品族扩展非常困难。 3.抽象工厂模式的使用场景 一个对象族(或是一组没有任何关系的对象)都有相同的约束，则可以使用抽象工厂模式。 github示例:抽象工厂模式 友情链接：(大佬)SnoWalker’s Blog","link":"/2018/12/04/設計模式之抽象工厂模式/"},{"title":"設計模式之命令模式","text":"命令模式介绍 定义 命令模式是一个高内聚的模式，将一个请求封装成一个对象，从而让你使用不同的请求把客户端参数化，对请求排队或者记录请求日志，可以提供命令的撤销和恢复功能。 角色 Receive接受者角色:该角色就是干活的角色，命令传递到这里是应该被执行的. Command命令角色：需要执行所有命令都在这里声明。 Invoker调用者角色：接受到命令，并执行命令。 命令模式的应用1.命令模式的优点 类间解耦 调用者角色与接受者角色之间没有任何依赖关系，调用者实现功能时只需要调用Command抽象类的execute方法就可以了，不需要了解到底哪个接受者执行了。 可扩展性 Command的子类可以非常容易的扩展，而调用者Invoker和高层次的模块Client不产生严重的代码耦合。 命令模式结合其他模式会更优秀 命令模式可以结合责任链模式，实现命令族解析，结合模板方法模式，则可以减少Command子类的膨胀问题。 2.命令模式的缺点 如果有N个命令，问题就出来了，Command的子类就可不是几个，而是N个，这个类膨胀的非常大，这个就需要读者在项目中慎重的考虑。 github示例:单例模式 友情链接：(大佬)SnoWalker’s Blog","link":"/2018/12/06/設計模式之命令模式/"},{"title":"設計模式之模板方法模式","text":"模板方法模式介紹模板方法模式(Template Method Pattern):定义一个操作中的算法的框架，而将一些步骤延迟到子类中。使得子类可以不改变一个算法的结构即可重定义该算法的某些特定的步骤。 模板方法模式的应用1.模板方法模式的优点 封装不变部分，扩展可变部分。把认为是不变部分的算法封装到父类实现，而可变部分的则可以通过类继承来继续扩展。 提取公共部分代码，便于维护。 行为由父类控制，子类实现。基本方法都是由子类实现的，因此子类可以通过扩展的方式增加相应的功能，符合开闭原则。 2.模板方法模式的缺点 按照我们的设计习惯，抽象类负责声明最抽象、最一般的事物属性和方法，实现类完成具体的事物属性和方法。但是模板方法模式缺颠倒了，抽象类定义了部分抽象方法，由子类实现，子类的执行结果影响了父类的结果，也就是子类对父类产生了影响，这在复杂的项目中，会带来代码阅读的难度，而且也会让新手产生不适感。 3.模板方法模式的使用场景 多个子类有公有的方法，并且逻辑基本相同时。 重要、复杂的算法，可以把核心算法设计为模板方法，周边的相关细节功能则有各个子类实现。 重构时，模板方法模式是一个经常使用的模式，把相同的代码抽象到父类中，然后通过钩子函数约束其行为。 github示例: 模板方法模式 友情链接：(大佬)SnoWalker’s Blog","link":"/2018/12/04/設計模式之模板方法模式/"},{"title":"SpringBoot整合HBase","text":"前言SpringBoot整合HBase 废话不多说，开始步入正题！第一步，映入Maven依赖 &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-client&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-hadoop&lt;/artifactId&gt; &lt;version&gt;2.5.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; 第二步，加入SpringBoot配置文件hbase.zookeeper.quorum=ip hbase.zookeeper.port=2181 第三步，引用HbaseTemplate,测试类使用方式@Autowired private HbaseTemplate hbaseTemplate; @Test public void contextLoads() { } @Test public void testPut() { hbaseTemplate.put(&quot;t&quot;, &quot;1&quot;, &quot;f&quot;, &quot;name&quot;, Bytes.toBytes(&quot;Alice&quot;)); hbaseTemplate.put(&quot;t&quot;, &quot;1&quot;, &quot;f&quot;, &quot;phone&quot;, Bytes.toBytes(&quot;15620974206&quot;)); } @Test public void testQuery(){ List&lt;String&gt; rows = hbaseTemplate.find(&quot;t&quot;, &quot;f&quot;, &quot;phone&quot;, new RowMapper&lt;String&gt;() { @Override public String mapRow(Result result, int i) throws Exception { return result.toString(); } }); System.out.println(JSONArray.toJSONString(rows)); List&lt;String&gt; rowli= hbaseTemplate.find(&quot;t&quot;, &quot;f&quot;, new RowMapper&lt;String&gt;() { @Override public String mapRow(Result result, int i) throws Exception { return result.toString(); } }); System.out.println(JSONArray.toJSONString(rowli)); } //依据表名，行号，列族，列名获取数据 @Test public void testCreateTable(){ if(hbaseTemplate.getConfiguration()==null){ System.out.println(&quot;为啥是空的呢&quot;); } String ls = hbaseTemplate.get(&quot;t&quot;, &quot;1&quot;,&quot;f&quot;, &quot;name&quot;, new RowMapper&lt;String&gt;() { @Override public String mapRow(Result result,int i)throws Exception{ List&lt;Cell&gt; cellList=result.listCells(); String res=&quot;&quot;; for(Cell cell:cellList){ res=Bytes.toString(cell.getValueArray(),cell.getValueOffset(),cell.getValueLength()); } return res; } }); System.out.println(ls); } 将使用原生的ConnectionFactory.createConnection进行调用HBASEimport com.hispeed.hbase.label.entity.R; import org.apache.hadoop.hbase.*; import org.apache.hadoop.hbase.client.*; import org.apache.hadoop.hbase.client.coprocessor.AggregationClient; import org.apache.hadoop.hbase.client.coprocessor.LongColumnInterpreter; import org.apache.hadoop.hbase.filter.FilterBase; import org.apache.hadoop.hbase.util.Bytes; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.data.hadoop.hbase.HbaseTemplate; import org.springframework.stereotype.Component; import java.io.IOException; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; @Component public class Hbase { protected Logger logger = LoggerFactory.getLogger(getClass()); private Connection connection; public Hbase(HbaseTemplate hbaseTemplate){ try { connection = ConnectionFactory.createConnection(hbaseTemplate.getConfiguration()); } catch (IOException e) { e.printStackTrace(); } } public boolean createTable(String tableName, String familyName) { try { logger.info(&quot;检查表{}是否存在&quot;, tableName); if (connection.getAdmin().tableExists(TableName.valueOf(tableName))) { logger.info(&quot;表{}已存在&quot;, tableName); return true; } HTableDescriptor hTableDescriptor = new HTableDescriptor(TableName.valueOf(tableName)); HColumnDescriptor hColumnDescriptor = new HColumnDescriptor(familyName); hTableDescriptor.addFamily(hColumnDescriptor); connection.getAdmin().createTable(hTableDescriptor); logger.info(&quot;表{}已创建&quot;, tableName); } catch (IOException e) { e.printStackTrace(); return false; } return true; } public R insertData(String tableName, String familyName, String rowKey, Map&lt;String, String&gt; map) { try { if (!connection.getAdmin().tableExists(TableName.valueOf(tableName))) { logger.info(&quot;表{}不存在&quot;, tableName); return R.error(&quot;101&quot;, &quot;表不存在&quot;); } //HTable继承Table HTable hTable = (HTable) connection.getTable(TableName.valueOf(tableName)); Put put = new Put(rowKey.getBytes(), rowKey.length()); for (Map.Entry&lt;String, String&gt; entry : map.entrySet()) { KeyValue kv = new KeyValue(rowKey.getBytes(), 0, rowKey.getBytes().length, familyName.getBytes(), 0, familyName.getBytes().length, entry.getKey().getBytes(), 0, entry.getKey().getBytes().length, System.currentTimeMillis(), KeyValue.Type.Put, entry.getValue().getBytes(), 0, entry.getValue().getBytes().length); put.add(kv); } hTable.put(put); logger.info(&quot;插入成功&quot;); } catch (IOException e) { e.printStackTrace(); return R.error(&quot;999&quot;, &quot;插入HBase数据异常&quot;); } return R.ok(); } public &lt;T extends FilterBase&gt; List&lt;Map&lt;String,String &gt;&gt; queryResult(T filter, int count, String tableName,String familyName) { Scan scan = new Scan(); scan.setFilter(filter); try { if (!connection.getAdmin().tableExists(TableName.valueOf(tableName))) { logger.info(&quot;表{}不存在&quot;, tableName); return null; } HTable hTable = (HTable) connection.getTable(TableName.valueOf(tableName)); ResultScanner scanner=hTable.getScanner(scan); List&lt;Map&lt;String,String &gt;&gt; list=new ArrayList&lt;&gt;(); int ct=0; for (Result result : scanner) { Map&lt;String,String&gt; map=new HashMap(); List&lt;Cell&gt; cellList=result.listCells(); for(Cell cell : cellList){ String key= Bytes.toString(cell.getQualifierArray(),cell.getQualifierOffset(),cell.getQualifierLength()); String value= Bytes.toString(cell.getValueArray(),cell.getValueOffset(),cell.getValueLength()); map.put(key,value); } list.add(map); logger.info(&quot;查询数据的索引为&quot;+ct); if(list.size()&gt;=count){ break; } ct++; } scanner.close(); return list; } catch (IOException e) { e.printStackTrace(); } return null; } public &lt;T extends FilterBase&gt; long query(T filter ,String tableName,String familyName){ long rowCount = 0; Scan scan = new Scan(); scan.setFilter(filter); scan.addFamily(Bytes.toBytes(familyName)); AggregationClient ac = new AggregationClient(connection.getConfiguration()); try { rowCount = ac.rowCount(TableName.valueOf(tableName), new LongColumnInterpreter(), scan); }catch (Throwable throwable){ logger.info(throwable.getMessage(), throwable); } return rowCount; } public boolean isClose(){ try { connection.close(); } catch (IOException e) { e.printStackTrace(); return false; } return true; } } 宾曰：感谢踏雪大佬的指导，学如逆水行舟，不进则退","link":"/2018/06/20/SpringBoot整合HBase/"},{"title":"分布式全局唯一ID生成策略","text":"分布式系统的定义 分布式系统就是对外是统一的入口，对内是有很多计算机服务组装的系统。 为什么需要一个全局唯一主键 主要是用于某个记录的存储或者输出的时候，能找到唯一的记录，不能让数据错乱。数据库的唯一ID在单库单表的情况下可以使用，但是在使用分布式系统的时候，数据库的自增主键就不可以使用了.举个栗子：先有订单记录表1024张,如果使用数据库中的自增主键，那么就会有1024订单号相同的订单，这个肯定是不行的，所以需要分布式唯一的主键去确定订单号。 分布式唯一主键的需求 最基本也是最重要的：全局唯一，不可重复 有一定的连续性:数据库存储使用的是B-TREE数据结构存储，我们要尽量保证ID是有序的增长 主键上需要能看到数据的记录位置 分布式唯一主键生成的方式1.UUID生成唯一主键1UUID.randomUUID() 优点 使用方便，性能高，无网络或者IO消耗. 缺点 无法作为DB主键使用，但是可以对于分布式链路追踪ID可以适用 长度太长：36位 2.使用Redis生成唯一的主键 使用redis的原子incr操作，保证实现主键递增； 优点 不依赖数据库，性能高 主键自然增长，能均匀分布到数据库中 缺点 需要引入redis并且需要维护自增的主键key,自增到什么长度数据合适(需要考虑) 对于redis性能有要求 3.数据库自增ID机制 依据插入数据库返回的数据主键进行计算出主键,即是需要逻辑的索引库，库的作用就是获取序列。 优点 简单有序。充分利用数据库的自增 缺点 生成ID需要读写数据库 对数据库的性能保障有要求 4.SnowFlake雪花算法 优点 简单高效,不依赖外部组件 按照时间有序递增 12位序列：毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号 缺点 依赖机器的时钟，如果时钟回拨，会造成ID重复 分布式环境下，机器时钟不是同步，会出现ID不是递增的情况 附带SnowFlake雪花算法(Java)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146/** * Twitter_Snowflake&lt;br&gt; * SnowFlake的结构如下(每部分用-分开):&lt;br&gt; * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &lt;br&gt; * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0&lt;br&gt; * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截) * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。 * 41位的时间截，可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69&lt;br&gt; * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId&lt;br&gt; * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号&lt;br&gt; * 加起来刚好64位，为一个Long型。&lt;br&gt; * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高， * 经测试，SnowFlake每秒能够产生26万ID左右。 */public class SnowflakeIdWorker { // ==============================Fields=========================================== /** 开始时间截 (2015-01-01) */ private final long twepoch = 1420041600000L; /** 机器id所占的位数 */ private final long workerIdBits = 5L; /** 数据标识id所占的位数 */ private final long datacenterIdBits = 5L; /** 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */ private final long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); /** 支持的最大数据标识id，结果是31 */ private final long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); /** 序列在id中占的位数 */ private final long sequenceBits = 12L; /** 机器ID向左移12位 */ private final long workerIdShift = sequenceBits; /** 数据标识id向左移17位(12+5) */ private final long datacenterIdShift = sequenceBits + workerIdBits; /** 时间截向左移22位(5+5+12) */ private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; /** 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */ private final long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); /** 工作机器ID(0~31) */ private long workerId; /** 数据中心ID(0~31) */ private long datacenterId; /** 毫秒内序列(0~4095) */ private long sequence = 0L; /** 上次生成ID的时间截 */ private long lastTimestamp = -1L; //==============================Constructors===================================== /** * 构造函数 * @param workerId 工作ID (0~31) * @param datacenterId 数据中心ID (0~31) */ public SnowflakeIdWorker(long workerId, long datacenterId) { if (workerId &gt; maxWorkerId || workerId &lt; 0) { throw new IllegalArgumentException(String.format(\"worker Id can't be greater than %d or less than 0\", maxWorkerId)); } if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) { throw new IllegalArgumentException(String.format(\"datacenter Id can't be greater than %d or less than 0\", maxDatacenterId)); } this.workerId = workerId; this.datacenterId = datacenterId; } // ==============================Methods========================================== /** * 获得下一个ID (该方法是线程安全的) * @return SnowflakeId */ public synchronized long nextId() { long timestamp = timeGen(); //如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常 if (timestamp &lt; lastTimestamp) { throw new RuntimeException( String.format(\"Clock moved backwards. Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp)); } //如果是同一时间生成的，则进行毫秒内序列 if (lastTimestamp == timestamp) { sequence = (sequence + 1) &amp; sequenceMask; //毫秒内序列溢出 if (sequence == 0) { //阻塞到下一个毫秒,获得新的时间戳 timestamp = tilNextMillis(lastTimestamp); } } //时间戳改变，毫秒内序列重置 else { sequence = 0L; } //上次生成ID的时间截 lastTimestamp = timestamp; //移位并通过或运算拼到一起组成64位的ID return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) // | (datacenterId &lt;&lt; datacenterIdShift) // | (workerId &lt;&lt; workerIdShift) // | sequence; } /** * 阻塞到下一个毫秒，直到获得新的时间戳 * @param lastTimestamp 上次生成ID的时间截 * @return 当前时间戳 */ protected long tilNextMillis(long lastTimestamp) { long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) { timestamp = timeGen(); } return timestamp; } /** * 返回以毫秒为单位的当前时间 * @return 当前时间(毫秒) */ protected long timeGen() { return System.currentTimeMillis(); } //==============================Test============================================= /** 测试 */ public static void main(String[] args) { SnowflakeIdWorker idWorker = new SnowflakeIdWorker(0, 0); for (int i = 0; i &lt; 1000; i++) { long id = idWorker.nextId(); System.out.println(Long.toBinaryString(id)); System.out.println(id); } }}","link":"/2019/03/07/分布式全局唯一ID生成策略/"},{"title":"手写JSON解析器","text":"一、JSON定义 JSON(JavaScript Object Notation, JS 对象简谱) 是一种轻量级的数据交换格式。 二、JSON解析器2.1 思路解析 定义一个枚举类存储JSON字符串里面需要特殊处理的类，例如：{}，“”等. 定义一个类存储JSON字符串的每个位置已经对应上述的类型. 定义数据去存储第二部产生的类对象 依据第三步产生的数组依据每个类型去循环处理数据 需要特殊处理String,既可以作为key也可以作为value 定义JSONOBJECT对象，内部存储用map 2.2具体操作如下 分析JSON储存数据格式以及需要特殊处理的符号，整理如下： token 含义 NULL null NUMBER 数字 STRING 字符串 BOOLEAN true/false SEP_COLON : SEP_COMMA , BEGIN_OBJECT { END_OBJECT } BEGIN_ARRAY [ END_ARRAY ] END_DOCUMENT 表示JSON数据结束 依据上面处理的逻辑定义如下枚举类 12345678910111213141516171819202122232425262728293031323334public enum TokenTypeEnum { /**object开始的编号**/ BEGIN_OBJECT(1), /**object结束的编号**/ END_OBJECT(2), /**数组开始的编号**/ BEGIN_ARRAY(4), /**数组结束的编号**/ END_ARRAY(8), /**null的编号**/ NULL(16), /**数字的编号**/ NUMBER(32), /**string的编号**/ STRING(64), /**Boolean的编号**/ BOOLEAN(128), /**每个类型的编号**/ SEP_COLON(256), /**编号**/ SEP_COMMA(512), /**文档编号**/ END_DOCUMENT(1024); /**每个类型的编号**/ private int code; TokenTypeEnum(int code) { this.code = code; } public int getTokenCode() { return code; }} 定义基础处理类 123456789101112131415161718192021222324252627282930313233343536373839404142package com.json.demo.tokenizer;/** * @author yebin * @version 1.0 * @className Token * @description 存储对应字符串 * @date 2019/4/1 16:25 **/public class Token { private TokenTypeEnum tokenType; private String value; public Token(TokenTypeEnum tokenType, String value) { this.tokenType = tokenType; this.value = value; } public TokenTypeEnum getTokenType() { return tokenType; } public void setTokenType(TokenTypeEnum tokenType) { this.tokenType = tokenType; } public String getValue() { return value; } public void setValue(String value) { this.value = value; } @Override public String toString() { return \"Token{\" + \"tokenType=\" + tokenType + \", value='\" + value + '\\'' + '}'; }} 定义数组 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.json.demo.tokenizer;import java.util.ArrayList;import java.util.List;/** * @author yebin * @version 1.0 * @className TokenList * @description 存储解析流 * @date 2019/4/1 16:30 **/public class TokenList { private List&lt;Token&gt; tokens = new ArrayList&lt;Token&gt;(); private int index = 0; public void add(Token token) { tokens.add(token); } public Token peek() { return index &lt; tokens.size() ? tokens.get(index) : null; } public Token peekPrevious() { return index - 1 &lt; 0 ? null : tokens.get(index - 2); } public Token next() { return tokens.get(index++); } public boolean hasMore() { return index &lt; tokens.size(); } @Override public String toString() { return \"TokenList{\" + \"tokens=\" + tokens + '}'; }} 定义处理类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325package com.json.demo.tokenizer;import com.json.demo.exception.JsonParseException;import jdk.nashorn.internal.parser.TokenType;import java.io.IOException;/** * @author yebin * @version 1.0 * @className Tokenizer * @description 词法解析 * @date 2019/4/1 16:35 **/public class Tokenizer { private ReaderChar readerChar; private TokenList tokenList; public TokenList getTokenStream(ReaderChar readerChar) throws IOException { this.readerChar = readerChar; tokenList = new TokenList(); // 词法解析，获取token流 tokenizer(); return tokenList; } /** * 将JSON文件解析成token流 * @throws IOException */ private void tokenizer() throws IOException { Token token; do { token = start(); tokenList.add(token); } while (token.getTokenType() != TokenTypeEnum.END_DOCUMENT); } /** * 解析过程的具体实现方法 * @return * @throws IOException * @throws JsonParseException */ private Token start() throws IOException, JsonParseException { char ch; //先读一个字符，若为空白符（ASCII码在[0, 20H]上）则接着读，直到刚读的字符非空白符 while (true){ if (!readerChar.hasMore()) { return new Token(TokenTypeEnum.END_DOCUMENT, null); } ch = readerChar.next(); if (!isWhiteSpace(ch)) { break; } } switch (ch) { case '{': return new Token(TokenTypeEnum.BEGIN_OBJECT, String.valueOf(ch)); case '}': return new Token(TokenTypeEnum.END_OBJECT, String.valueOf(ch)); case '[': return new Token(TokenTypeEnum.BEGIN_ARRAY, String.valueOf(ch)); case ']': return new Token(TokenTypeEnum.END_ARRAY, String.valueOf(ch)); case ',': return new Token(TokenTypeEnum.SEP_COMMA, String.valueOf(ch)); case ':': return new Token(TokenTypeEnum.SEP_COLON, String.valueOf(ch)); case 'n': return readNull(); case 't': case 'f': return readBoolean(); case '\"': return readString(); case '-': return readNumber(); } if (isDigit(ch)) { return readNumber(); } throw new JsonParseException(\"Illegal character\"); } /** 以下方法用来判断所属数据类型是否合法 */ // 判断一个字符是否属于空白字符 private boolean isWhiteSpace(char ch) { return (ch == ' ' || ch == '\\t' || ch == '\\r' || ch == '\\n'); } private Token readString() throws IOException { StringBuilder sb = new StringBuilder(); while(true) { char ch = readerChar.next(); // 处理转义字符 if (ch == '\\\\') { if (!isEscape()) { throw new JsonParseException(\"Invalid escape character\"); } sb.append('\\\\'); ch = readerChar.peek(); sb.append(ch); // 处理 Unicode 编码，形如 \\u4e2d。且只支持 \\u0000 ~ \\uFFFF 范围内的编码 if (ch == 'u') { for (int i = 0; i &lt; 4; i++) { ch = readerChar.next(); if (isHex(ch)) { sb.append(ch); } else { throw new JsonParseException(\"Invalid character\"); } } } // 碰到另一个双引号，则认为字符串解析结束，返回 Token } else if (ch == '\"') { return new Token(TokenTypeEnum.STRING, sb.toString()); // 传入的 JSON 字符串不允许换行 } else if (ch == '\\r' || ch == '\\n') { throw new JsonParseException(\"Invalid character\"); } else { sb.append(ch); } } } /** * 判断是否有乱传转义字符 * @return * @throws IOException */ private boolean isEscape() throws IOException { char ch = readerChar.next(); return (ch == '\"' || ch == '\\\\' || ch == 'u' || ch == 'r' || ch == 'n' || ch == 'b' || ch == 't' || ch == 'f' || ch == '/'); } /** * 判断是否是十六进制数 * @param ch * @return */ private boolean isHex(char ch) { return ((ch &gt;= '0' &amp;&amp; ch &lt;= '9') || ('a' &lt;= ch &amp;&amp; ch &lt;= 'f') || ('A' &lt;= ch &amp;&amp; ch &lt;= 'F')); } /** * 判断是否是整数 * @return * @throws IOException */ private Token readNumber() throws IOException { char ch = readerChar.peek(); StringBuilder sb = new StringBuilder(); // 处理负数 if (ch == '-') { sb.append(ch); ch = readerChar.next(); // 处理 -0.xxxx if (ch == '0') { sb.append(ch); sb.append(readFracAndExp()); } else if (isDigitOneToNine(ch)) { do { sb.append(ch); ch = readerChar.next(); } while (isDigit(ch)); if (ch != (char) -1) { readerChar.back(); sb.append(readFracAndExp()); } } else { throw new JsonParseException(\"Invalid minus number\"); } } else if (ch == '0') { // 处理小数 sb.append(ch); sb.append(readFracAndExp()); } else { do { sb.append(ch); ch = readerChar.next(); } while (isDigit(ch)); if (ch != (char) -1) { readerChar.back(); sb.append(readFracAndExp()); } } return new Token(TokenTypeEnum.NUMBER, sb.toString()); } /** * 判断是否是指数 * @param ch * @return * @throws IOException */ private boolean isExp(char ch) throws IOException { return ch == 'e' || ch == 'E'; } /** * 判断范围[0,9] * @param ch * @return */ private boolean isDigit(char ch) { return ch &gt;= '0' &amp;&amp; ch &lt;= '9'; } /** * 判断范围[1,9] * @param ch * @return */ private boolean isDigitOneToNine(char ch) { return ch &gt;= '1' &amp;&amp; ch &lt;= '9'; } private String readFracAndExp() throws IOException { StringBuilder sb = new StringBuilder(); char ch = readerChar.next(); if (ch == '.') { sb.append(ch); ch = readerChar.next(); if (!isDigit(ch)) { throw new JsonParseException(\"Invalid frac\"); } do { sb.append(ch); ch = readerChar.next(); } while (isDigit(ch)); if (isExp(ch)) { // 处理科学计数法 sb.append(ch); sb.append(readExp()); } else { if (ch != (char) -1) { readerChar.back(); } } } else if (isExp(ch)) { sb.append(ch); sb.append(readExp()); } else { readerChar.back(); } return sb.toString(); } /** * 处理指数形式的数据 * @return * @throws IOException */ private String readExp() throws IOException { StringBuilder sb = new StringBuilder(); char ch = readerChar.next(); if (ch == '+' || ch =='-') { sb.append(ch); ch = readerChar.next(); if (isDigit(ch)) { do { sb.append(ch); ch = readerChar.next(); } while (isDigit(ch)); if (ch != (char) -1) { // 读取结束，不用回退 readerChar.back(); } } else { throw new JsonParseException(\"e or E\"); } } else { throw new JsonParseException(\"e or E\"); } return sb.toString(); } /** * 判断是否是true or false * @return * @throws IOException */ private Token readBoolean() throws IOException { if (readerChar.peek() == 't') { if (!(readerChar.next() == 'r' &amp;&amp; readerChar.next() == 'u' &amp;&amp; readerChar.next() == 'e')) { throw new JsonParseException(\"Invalid json string\"); } return new Token(TokenTypeEnum.BOOLEAN, \"true\"); } else { if (!(readerChar.next() == 'a' &amp;&amp; readerChar.next() == 'l' &amp;&amp; readerChar.next() == 's' &amp;&amp; readerChar.next() == 'e')) { throw new JsonParseException(\"Invalid json string\"); } return new Token(TokenTypeEnum.BOOLEAN, \"false\"); } } /** * 词法分析器在读取字符n后，期望后面的三个字符分别是u,l,l，与 n 组成词 null。 * 如果满足期望，则返回类型为 NULL 的 Token，否则报异常。 */ private Token readNull() throws IOException { if (!(readerChar.next() == 'u' &amp;&amp; readerChar.next() == 'l' &amp;&amp; readerChar.next() == 'l')) { throw new JsonParseException(\"Invalid json string\"); } return new Token(TokenTypeEnum.NULL, \"null\"); }} 具体逻辑地址 github地址 友情链接：(大佬)SnoWalker’s Blog","link":"/2019/04/02/手写JSON解析器/"},{"title":"手写简易SpringMVC框架","text":"序一直在用Spring开发,自我感觉需要不能做这样的事情： “虽知其然，而未必知其所以然也” 于是，天空一声巨响，这篇博客诞生了。。。。 一、了解SpringMVC运行流程及九大组件1.SpringMVC运行流程 用户发送请求至前端控制器DispatcherServlet DispatcherServlet收到请求调用HandlerMapping处理器映射器 处理器映射器根据请求url找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet DispatcherServlet通过HandlerAdapter处理器适配器调用处理器 执行处理器(Controller，也叫后端控制器) Controller执行完成返回ModelAndView HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet DispatcherServlet将ModelAndView传给ViewReslover视图解析器 ViewReslover解析后返回具体View DispatcherServlet对View进行渲染视图（即将模型数据填充至视图中） DispatcherServlet响应用户 2.SpringMVC的九大组件12345678910111213141516171819202122232425protected void initStrategies(ApplicationContext context) { //用于处理上传请求。处理方法是将普通的request包装成MultipartHttpServletRequest，后者可以直接调用getFile方法获取File. initMultipartResolver(context); //SpringMVC主要有两个地方用到了Locale：一是ViewResolver视图解析的时候；二是用到国际化资源或者主题的时候。 initLocaleResolver(context); //用于解析主题。SpringMVC中一个主题对应一个properties文件，里面存放着跟当前主题相关的所有资源、 //如图片、css样式等。SpringMVC的主题也支持国际化， initThemeResolver(context); //用来查找Handler的。 initHandlerMappings(context); //从名字上看，它就是一个适配器。Servlet需要的处理方法的结构却是固定的，都是以request和response为参数的方法。 //如何让固定的Servlet处理方法调用灵活的Handler来进行处理呢？这就是HandlerAdapter要做的事情 initHandlerAdapters(context); //其它组件都是用来干活的。在干活的过程中难免会出现问题，出问题后怎么办呢？ //这就需要有一个专门的角色对异常情况进行处理，在SpringMVC中就是HandlerExceptionResolver。 initHandlerExceptionResolvers(context); //有的Handler处理完后并没有设置View也没有设置ViewName，这时就需要从request获取ViewName了， //如何从request中获取ViewName就是RequestToViewNameTranslator要做的事情了。 initRequestToViewNameTranslator(context); //ViewResolver用来将String类型的视图名和Locale解析为View类型的视图。 //View是用来渲染页面的，也就是将程序返回的参数填入模板里，生成html（也可能是其它类型）文件。 initViewResolvers(context); //用来管理FlashMap的，FlashMap主要用在redirect重定向中传递参数。 initFlashMapManager(context); } 二、了解SpringMVC运行流程及九大组件1、读取配置 从图中可以看出，SpringMVC本质上是一个Servlet,这个 Servlet 继承自 HttpServlet。FrameworkServlet负责初始化SpringMVC的容器，并将Spring容器设置为父容器 2、初始化阶段在前面我们提到DispatcherServlet的initStrategies方法会初始化9大组件，但是这里将实现一些SpringMVC的最基本的组件而不是全部，按顺序包括： 加载配置文件 扫描用户配置包下面所有的类 拿到扫描到的类，通过反射机制，实例化。并且放到ioc容器中(Map的键值对 beanName-bean) beanName默认是首字母小写 初始化HandlerMapping，这里其实就是把url和method对应起来放在一个k-v的Map中,在运行阶段取出 3、运行阶段每一次请求将会调用doGet或doPost方法，所以统一运行阶段都放在doDispatch方法里处理，它会根据url请求去HandlerMapping中匹配到对应的Method，然后利用反射机制调用Controller中的url对应的方法，并得到结果返回。按顺序包括以下功能： 异常的拦截 获取请求传入的参数并处理参数 通过初始化好的handlerMapping中拿出url对应的方法名，反射调用 三、实现自己的SpringMVC框架工程目录结构如下： MyDispatcherServlet核心类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275package com.yebin.servlet;import com.yebin.annotation.MyController;import com.yebin.annotation.MyRequestMapping;import com.yebin.annotation.MyRequestParam;import javax.servlet.ServletConfig;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.File;import java.io.IOException;import java.io.InputStream;import java.lang.annotation.Annotation;import java.lang.reflect.Method;import java.net.URL;import java.util.*;/** * @author 17611 * @version 1.0 * @className MyDispatcherServlet * @description 初始化核心处理器 * @date 2019/4/9 13:58 **/public class MyDispatcherServlet extends HttpServlet { private static final long serialVersionUID = 1505205806194854425L; /** * 读取配置文件 */ private Properties properties = new Properties(); /** * 存储扫描包下面所有的类 */ private List&lt;String&gt; classNames = new ArrayList&lt;String&gt;(); /** * 存储key=url value为类（controller） */ private Map&lt;String, Object&gt; ioc = new HashMap&lt;String, Object&gt;(); /** * 存储key=url value为方法 */ private Map&lt;String, Method&gt; handlerMapping = new HashMap&lt;String, Method&gt;(); /** * 存储key=url value为类（对应实际的类方法） */ private Map&lt;String, Object&gt; controllerMap = new HashMap&lt;String, Object&gt;(); @Override public void init(ServletConfig config) throws ServletException { //1.加载配置文件 doLoadConfig(config.getInitParameter(\"contextConfigLocation\")); //2.初始化所有相关联的类,扫描用户设定的包下面所有的类 doScanner(properties.getProperty(\"scanPackage\")); //3.拿到扫描到的类,通过反射机制,实例化,并且放到ioc容器中(k-v beanName-bean) beanName默认是首字母小写 doInstance(); //4.初始化HandlerMapping(将url和method对应上) initHandlerMapping(); } @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { try { //处理请求 doDispatch(req, resp); } catch (Exception e) { resp.getWriter().write(\"500!! Server Exception\"); } } @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { try { //处理请求 doDispatch(req, resp); } catch (Exception e) { resp.getWriter().write(\"500!! Server Exception\"); } } private void doDispatch(HttpServletRequest req, HttpServletResponse resp) throws Exception { if (handlerMapping.isEmpty()) { return; } String url = req.getRequestURI(); String contextPath = req.getContextPath(); System.out.println(\"url=\" + url); System.out.println(\"contextPath=\" + contextPath); url = url.replace(contextPath, \"\").replaceAll(\"/+\", \"/\"); if (!this.handlerMapping.containsKey(url)) { resp.getWriter().write(\"404 NOT FOUND!\"); return; } Method method = this.handlerMapping.get(url); //获取方法的参数列表 Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); Annotation[][] parameterAnnotations = method.getParameterAnnotations(); //获取请求的参数 Map&lt;String, String[]&gt; parameterMap = req.getParameterMap(); //保存参数值 Object[] paramValues = new Object[parameterTypes.length]; //方法的参数列表 for (int i = 0; i &lt; parameterTypes.length; i++) { //根据参数名称，做某些处理 String requestParam = parameterTypes[i].getSimpleName(); if (requestParam.equals(\"HttpServletRequest\")) { //参数类型已明确，这边强转类型 paramValues[i] = req; continue; } if (requestParam.equals(\"HttpServletResponse\")) { paramValues[i] = resp; continue; } Annotation[] parameterAnnotation = parameterAnnotations[i]; for (Annotation annotation : parameterAnnotation) { if (annotation instanceof MyRequestParam) { MyRequestParam myRequestParam = (MyRequestParam) annotation; if (!parameterMap.containsKey(myRequestParam.value())) { throw new RuntimeException(myRequestParam.value() + \"参数不存在\"); } System.out.println(myRequestParam.value()); String value = Arrays.toString(parameterMap.get(myRequestParam.value())).replaceAll(\"\\\\[|\\\\]\", \"\").replaceAll(\",\\\\s\", \",\"); if (requestParam.equals(\"Integer\")) { paramValues[i] = Integer.parseInt(value); } else if (requestParam.equals(\"String\")) { paramValues[i] = value; } } } } //利用反射机制来调用 try { //第一个参数是method所对应的实例 在ioc容器中 System.out.println(Arrays.toString(paramValues)); method.invoke(this.controllerMap.get(url), paramValues); } catch (Exception e) { e.printStackTrace(); } } private void doLoadConfig(String location) { //把web.xml中的contextConfigLocation对应value值的文件加载到流里面 if (location.startsWith(\"classpath:\")) { location = location.replace(\"classpath:\", \"\"); } else if (location.contains(\"/\")) { int lastSplitIndex = location.lastIndexOf('/'); location = location.substring(lastSplitIndex + 1, location.length()); } InputStream resourceAsStream = this.getClass().getClassLoader().getResourceAsStream(location); try { //用Properties文件加载文件里的内容 properties.load(resourceAsStream); } catch (IOException e) { e.printStackTrace(); } finally { //关流 if (null != resourceAsStream) { try { resourceAsStream.close(); } catch (IOException e) { e.printStackTrace(); } } } } private void doScanner(String packageName) { //把所有的.替换成/ System.out.println(packageName); URL url = this.getClass().getResource(\"/\" + packageName.replaceAll(\"\\\\.\", \"/\")); File dir = new File(url.getFile()); for (File file : dir.listFiles()) { if (file.isDirectory()) { //递归读取包 doScanner(packageName + \".\" + file.getName()); } else { String className = packageName + \".\" + file.getName().replace(\".class\", \"\"); classNames.add(className); } } } private void doInstance() { if (classNames.isEmpty()) { return; } for (String className : classNames) { try { //把类搞出来,反射来实例化(只有加@MyController需要实例化) Class&lt;?&gt; clazz = Class.forName(className); if (clazz.isAnnotationPresent(MyController.class)) { if (ioc.containsKey(toLowerFirstWord(clazz.getSimpleName()))) { continue; } ioc.put(toLowerFirstWord(clazz.getSimpleName()), clazz.newInstance()); } } catch (Exception e) { e.printStackTrace(); } } } private void initHandlerMapping() { if (ioc.isEmpty()) { return; } try { for (Map.Entry&lt;String, Object&gt; entry : ioc.entrySet()) { Class&lt;? extends Object&gt; clazz = entry.getValue().getClass(); if (!clazz.isAnnotationPresent(MyController.class)) { continue; } //拼url时,是controller头的url拼上方法上的url String baseUrl = \"\"; if (clazz.isAnnotationPresent(MyRequestMapping.class)) { MyRequestMapping annotation = clazz.getAnnotation(MyRequestMapping.class); baseUrl = annotation.value(); } Method[] methods = clazz.getMethods(); for (Method method : methods) { if (!method.isAnnotationPresent(MyRequestMapping.class)) { continue; } MyRequestMapping annotation = method.getAnnotation(MyRequestMapping.class); String url = annotation.value(); url = (baseUrl + \"/\" + url).replaceAll(\"/+\", \"/\"); handlerMapping.put(url, method); controllerMap.put(url, clazz.newInstance()); System.out.println(url + \",\" + method); } } } catch (Exception e) { e.printStackTrace(); } } /** * 把字符串的首字母小写 * * @param name * @return */ private String toLowerFirstWord(String name) { char[] charArray = name.toCharArray(); charArray[0] += 32; return String.valueOf(charArray); }} 方法说明 init()：加载配置文件以及初始化相关类 doLoadConfig():加载配置文件application.properties doInstance():拿到扫描到的类,通过反射机制,实例化,并且放到ioc容器中(k-v beanName-bean) beanName默认是首字母小写 initHandlerMapping():将URL与具体实现对应上 doDispatch():真实处理逻辑 总结以上就能完成基础的@Controller、@RequestMapping、@RequestParam注解起作用，其余SpringMVC功能读者可以尝试自己实现。 GitHub：https://github.com/SeekingPlumBlossoms/mySpringMvc.git 友情链接：(大佬)SnoWalker’s Blog","link":"/2019/04/11/手写简易SpringMVC框架/"},{"title":"深入理解Java虚拟机笔记---属性表集合","text":"在Class文件，字段表，方法表中都可以携带自己的属性表集合，以用于描述某些场景专有的信息。与Class文件中其它的数据项目要求的顺序、长度和内容不同，属性表集合的限制稍微宽松一些，不再要求各个属性表具有严格的顺序，并且只要不与已有的属性名重复，任何人实现的编译器都可以向属性表中写入自己定义的属性信息，Java虚拟机运行时会忽略掉它不认识的属性。为了能正确地解析Class文件，《Java虚拟机规范(第二版)》中预定义了9荐虚拟机实现应当能识别的属性，具体如下表所示：对于每个属性，它的名称需要从常量池中引用一个CONSTANT_Utf8_info类型的常量表来表示，而属性值的结构则是完全自定义的，只要说明属性值所占用的位数长度即可。一个符合规则的属性表应该满足如下表定义的结构： 1.Code属性Java程序方法体里的代码经过Javac编译器处理之后，最终变为字节码指令存储在Code属性内。Code属性出现在方法表的属性集合中，但并非所有方法都必须存在这个属性表，譬如接口或抽象类中的抽象方法就不存在Code属性，如果方法有Code属性表存在，那么它的结构如下表：attribute_name_index是一项指向CONSTANT_Utf8_info常量表的索引，常量值固定为“Code”，它代表了该属性的属性名称，attribute_length指示了属性值的长度，由于属性名称索引与属性长度一共是6个字节，所以属性值的长度固定为整个属性表的长度减去6个字节。max_stack代表了操作数栈(Operand Stacks)的最大深度。在方法执行的任意时刻，操作数栈都不会超过这个深度。虚拟机运行的时候需要根据这个值来分配栈帧(Frame)中的操作数栈深度。max_locals代表了局部变量表所需的存储空间。在这里，max_locals的单位是Slot，Slot是虚拟机为局部变量表分配内存所使用的最小单位。对于byte,char,float,int,shot,boolean,reference和returnAddress等长度不超过32位的数据类型，每个局部变量占1个Slot，而double与long这两种64位的数据类型而需要2个Slot来存放。方法参数(包括实例方法中的隐藏参数“this”)，显示异常处理器的参数(Exception Handler Parameter,即try-catch语句中catch块所定义的异常)，方法体中定义的局部变量都需要使用局部表来存放。另外，并不是在方法中使用了多个局部变量，就把这些局部变量所占的Slot之和作为max_locals的值，原因是局部变量表中的Slot可以重用，当代码执行超出一个局部变量的作用域时，这个局部变量所在的Slot就可以被其他局部变量所使用，编译器会根据变量的作用域来分类Slot并分配给各个变量使用，然后计算出max_locals的大小。 code_length和code用来存储Java源程序编译后生成的字节码指令。code_length代表字节码长度，code是用于存储字节码指令的一系列字节流。既然名为字节码指令，那么每个指令就是一个u1类型的单字节，当虚拟机读取到code中的一个字节码时，就可相应地找出这个字节码代表的是什么指令，并且可以知道这条指令后面是否需要跟随参数，以及参数应该如何理解。关于code_length还有一件值得注意的事情，虽然它是一个u4类型的长度值，理论上最大值可以达到2的32次方减1，但虚拟机规范中限制了一个方法不允许超过65535条字节码指令，如果超过这个限制，Javac编译器就会拒绝编译。一般来讲，只要我们写Java代码时不是刻意地编写超长的方法，就不会超过这个最大值限制。但是，在编译复杂的JSP文件中，可以会因为这个原因导致编译失败。Code属性是Class文件中最重要的一个属性，如果表一个Java程序中的信息分为代码(Code，方法体里的Java代码)和元数据(Metadata，包括类、字段、方法定义及其它信息)两部分，那么在整个Class文件里，Code属性用于描述代码，其它的所有数据项目就都用于描述元数据。在字节码指令之后的是这个方法的显示异常处理表，异常表对于Code属性表来说不是必须存在的。异常表的格式如下表：异常表它包含4个字段，这些字段的含义为：如果字节码从第start_pc到end_pc行之间(不包含第end_pc)行出现了类型为catch_type或其子类的异常(catch_type为指向一个CONSTANT_Class_info型常量的索引)，则转到第handler_pc行继续处理。当catch_type的值为0时，代表任何的异常情况都需要转向到handler_pc行行进行处理。异常表实际上是Java代码的一部分，编译器使用异常表而不是简单的跳转命令来实现Java异常及finally处理机制。注：字节码的“行”是一种形象的描述，指的是字节码相对于方法体开始的偏移量，而不是Java源代码的行号。 2.Exceptions属性这里的Exceptions属性是在方法表中与Code属性平级的一项属性，而不是Code属性表中的异常属性表。Exceptions属性表的作是列举出方法中可能抛出的受查检(Checked Exception)，也就是在方法描述时在throws关键字后面列举的异常。它的结构如下表： 此属性表中的number_of_exceptions项表示访求可能抛出number_of_exceptions种受检查异常，每一种受检查异常使用一个exception_index_table项表示，为指向常量池中CONSTANT_Class_info型常量表的索引，代表了该受检查异常的类型。 3.LineNumberTable属性LineNumberTable属性用于描述Java源代码行号与字节码行号(字节码偏移量)之间的对应关系。它并不是运行时必须的属性，但默认会生成到Class文件之中，可以在Javac中使用-g:none或-g:lines选项来取消或要求生成这项信息。如果选择不生成LineNumberTable属性表，对程序运行产生的最主要的影响就是在抛出异常时，堆栈中将不会显示出错的行号，并且在调试程序的时候无法按照源码来设置断点。LineNumberTable属性表结构如下表： line_number_table是一个数量为line_number_table_length，类型为line_number_info的集合，line_number_info表包括了start_pc和line_number两个u2类型的数据项，前者是字节码行号，后者是Java源码行号。 4.LocalVariableTable属性LocalVariableTable属性表用于描述栈帧中局部变量表中的变量与Java源码中定义的变量之间的关系，它不是运行时必须的属性，默认也不会生成到Class文件之中，可以使用-g:none或-g:vars选项来取消或要求生成这项信息。如果没有生成这项属性，最大的影响就是当其它人引用这个方法时，所有参数名称都丢失，IDE可能会使用诸如arg0、arg1之类的占位符来替换原有的参数名称，这对程序运行没有影响，但是会给代码编写带来较大的不便，而且在调试期间无法根据参数名称从运行上下文件中获取参数值。LocalVariableTable属性表结构如下： 其中local_variable_info项目代表了一个栈帧与源码中的局部变量的关联，结构如下： index是这个局部变量在栈帧局部变量表中的Slot位置。当这个变量的数据类型是64位时(double和long)，它占用的Slot为index和index+1两个位置。在JDK1.5引入了泛型之后，LocalVariableTable属性增加了一个“姐妹”属性：LocalVaiableTypeTable，这个新增加的属性结构与LocalVariableTable属性非常相似，仅仅是把记录字段描述符的descript_index替换成了字段的特征签名(Singnature)，对于非泛型类型来说，描述符的参数化类型被擦除掉了，描述符就不能准确地描述泛型类型了，因此出现了LocalVariableTypeTable属性。 5.SourceFile属性SourceFile属性用于记录这生成这个Class文件的源码文件名称。这个属性也是可选的，可以使用-g:none或-g:source选项来取消或要求生成这项信息。在Java中，对于大多数的类来说，类名和文件是一致的，但有一些特殊情况(如内部类)例外。如果不生成这项属性，当招聘异常时，堆栈中半不会显示出错误代码所属性文件名。这个属性是一个室长的属性，结构如下： sourcefile_index数据项是指向常量池中CONSTANT_Utf8_info型常量的索引，常量值是源文件的文件名。 6.ConstantValue属性ConstantValue属性的作用是通知虚拟机自动为静态变量赋值。只有被static关键字修饰的变量才可以使用这项属性。在Java程序里类类似“int x = 123“和”static int x = 123”这样的变量定义非常常见，但虚拟机对这两种变量赋值的方法和时刻有所不同。对于非static类型的变量(也就是实例变量)的赋值是在实例构造器方法中进行的；对于类变量，则有两种式可以选择：赋值在类构造器方法中进行，或者使用ConstantValue属性来赋值。目前Sun Javac编译器的选择是：如果同时使用final和static来修改一个变量，并且这个变量的数据类型是基本类型或java.lang.String的话，就生成ConstantValue属性来进行初始化，如果这个变量没有被final修饰，或者并非基本类型或字符串，则选择在类构造器中进行初始化。ConstantValue属性表结构如下： ConstantValue属性是一个定长属性，它的attribute_length数据项值必须为2。constantvalue_index数据项代表了常量池中一个字面常量的引用，根据字段类型不同，字面量可以是CONSTANT_Long_info,CONSTANT_Float_info,CONSTANT_Double_info,CONSTANT_Integer_info和CONSTANT_String_info常量中的一种。 7.InnerClasses属性InnerClasses属性表用于记录内部类与宿主类之间的关联。如果一个类中定义了内部类，那么编译器将会为它及它所包含的内部类生成InnerClasses属性表。表结构如下： 数据项number_of_classes代表需要记录多少个内部类信息，每一个内部类的类的信息都由一个inner_class_info表进行描述。inner_class_info表结构如下： inner_class_info_index和outer_class_info_index都是指向常量池中CONSTANT_Class_infon常量的索引，分别代表了内部类和宿主类的符号引用。inner_name_index是指向常量池中CONSTANT_Utf8_info型常量的索引，代表这个内部类的名称，如果是匿名内部类，则这项值为0。inner_class_access_flags是内部类的访问标志，类型于类的access_flags，它的取值范围如下表： 8.Deprecated及Synthetic属性Deprecated及Synthetic属性都属性于标志类型的布尔值属性，只存在有和没有的区别，没有属性值的概念。Deprecated属性用于表示某个类，字段或方法，已经被程序作者定为不再推荐使用，它可以通过代码中使用@Deprecated注解进行设置。Synthetic属代表此字段或方法并不是由Java源码直接产生的，而是由编译器自行添加的，在JDK1.5之后，标识一个类，字段或方法是编译器自动产生的，也可以设置它们访问标志中的ACC_SYNTHETIC标志位，其中最典型的就是Bridge Method。所有非用户代码生产的类，方法及字段都应当至少设置Synthetic属性和ACC_SYNTHETIC标志位中的一项，唯一的例外是实例构造器“”方法和类构造器“&lt;clinit”方法。 Deprecated及Synthetic属性表结构如下： 其中attribute_length数据项的值必须为0，因为没有任何属性值需要设置。 在JDK1.5和JDK1.6中一共增加了10项属性，具体如下：","link":"/2019/06/10/深入理解Java虚拟机笔记-属性表集合/"},{"title":"简化Mybatis框架","text":"序简化版的Mybatis,核心利用动态代理实现。 一、Mybatis流程简介 mybatis的配置文件有2类 mybatisconfig.xml，配置文件的名称不是固定的，配置了全局的参数的配置，全局只能有一个配置文件。 Mapper.xml 配置多个statemement，也就是多个sql，整个mybatis框架中可以有多个Mappe.xml配置文件。 通过mybatis配置文件得到SqlSessionFactory 通过SqlSessionFactory得到SqlSession，用SqlSession就可以操作数据了。 SqlSession通过底层的Executor（执行器），执行器有2类实现： 基本实现 带有缓存功能的实现 MappedStatement是通过Mapper.xml中定义statement生成的对象。 参数输入执行并输出结果集，无需手动判断参数类型和参数下标位置，且自动将结果集映射为Java对象 HashMap，KV格式的数据类型 Java的基本数据类型 POJO，java的对象 二、梳理自己的Mybatis的设计思路 读取xml文件，建立连接MyConfiguration负责与人交互。待读取xml后，将属性和连接数据库的操作封装在MyConfiguration对象中供后面的组件调用。本文将使用dom4j来读取xml文件，它具有性能优异和非常方便使用的特点。 创建SqlSession，搭建Configuration和Executor之间的桥梁 我们经常在使用框架时看到Session，Session到底是什么呢？一个Session仅拥有一个对应的数据库连接。类似于一个前段请求Request，它可以直接调用exec(SQL)来执行SQL语句。从流程图中的箭头可以看出，MySqlSession的成员变量中必须得有MyExecutor和MyConfiguration去集中做调配，箭头就像是一种关联关系。我们自己的MySqlSession将有一个getMapper方法，然后使用动态代理生成对象后，就可以做数据库的操作了。 创建Executor，封装JDBC操作数据库 Executor是一个执行器，负责SQL语句的生成和查询缓存（缓存还没完成）的维护，也就是jdbc的代码将在这里完成，不过本文只实现了单表，有兴趣的同学可以尝试完成多表。 创建MapperProxy，使用动态代理生成Mapper对象 我们只是希望对指定的接口生成一个对象，使得执行它的时候能运行一句sql罢了，而接口无法直接调用方法，所以这里使用动态代理生成对象，在执行时还是回到MySqlSession中调用查询，最终由MyExecutor做JDBC查询。这样设计是为了单一职责，可扩展性更强 二、实现自己的Mybatis 首先，新建一个maven项目，在pom.xml中导入以下依赖： 1234567891011121314151617181920&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 读取xml文件 --&gt; &lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySQL --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.29&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 创建我们的数据库xml配置文件： 1234567&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;database&gt; &lt;property name=\"driverClassName\"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=\"url\"&gt;jdbc:mysql://localhost:3306/test?useUnicode=true&amp;amp;characterEncoding=utf8&lt;/property&gt; &lt;property name=\"username\"&gt;root&lt;/property&gt; &lt;property name=\"password\"&gt;123456&lt;/property&gt;&lt;/database&gt; 然后在数据库创建test库，执行如下SQL语句： 1234567CREATE TABLE `user` ( `id` varchar(64) NOT NULL, `password` varchar(255) DEFAULT NULL, `username` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;INSERT INTO `test`.`user` (`id`, `password`, `username`) VALUES ('1', '123456', 'yebin'); 创建User实体类，和UserMapper接口和对应的xml文件: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.yb.bean;/** * @author yebin * @version 1.0 * @className User * @description 用户 * @date 2019/4/22 13:45 **/public class User { private String userName; private String id; private String password; public String getUserName() { return userName; } public User setUserName(String userName) { this.userName = userName; return this; } public String getId() { return id; } public User setId(String id) { this.id = id; return this; } public String getPassword() { return password; } public User setPassword(String password) { this.password = password; return this; } @Override public String toString() { return \"User{\" + \"userName='\" + userName + '\\'' + \", id='\" + id + '\\'' + \", password='\" + password + '\\'' + '}'; }} 123456&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;mapper nameSpace=\"com.yb.mapper.UserMapper\"&gt; &lt;select id=\"getUserById\" resultType =\"com.yb.bean.User\"&gt; select * from user where id = ? &lt;/select&gt;&lt;/mapper&gt; 基本操作配置完成，接下来我们开始实现MyConfiguration： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135package com.yb.sqlsession;import com.yb.config.Function;import com.yb.config.MapperBean;import org.dom4j.Document;import org.dom4j.DocumentException;import org.dom4j.Element;import org.dom4j.io.SAXReader;import java.io.InputStream;import java.sql.Connection;import java.sql.DriverManager;import java.sql.SQLException;import java.util.ArrayList;import java.util.Iterator;import java.util.List;/** * @author yebin * @version 1.0 * @className MyConfiguration * @description 读取配置文件 * @date 2019/4/22 14:01 **/public class MyConfiguration { private static ClassLoader loader = ClassLoader.getSystemClassLoader(); /** * 读取xml信息并处理 */ public static Connection build(String resource) { try { InputStream stream = loader.getResourceAsStream(resource); SAXReader reader = new SAXReader(); Document document = reader.read(stream); Element root = document.getRootElement(); return evalDataSource(root); } catch (Exception e) { throw new RuntimeException(\"error occured while evaling xml \" + resource); } } private static Connection evalDataSource(Element node) throws ClassNotFoundException { if (!node.getName().equals(\"database\")) { throw new RuntimeException(\"root should be &lt;database&gt;\"); } String driverClassName = null; String url = null; String username = null; String password = null; //获取属性节点 for (Object item : node.elements(\"property\")) { Element i = (Element) item; String value = getValue(i); String name = i.attributeValue(\"name\"); if (name == null || value == null) { throw new RuntimeException(\"[database]: &lt;property&gt; should contain name and value\"); } //赋值 if (\"url\".equals(name)) { url = value; } else if (\"username\".equals(name)) { username = value; } else if (\"password\".equals(name)) { password = value; } else if (\"driverClassName\".equals(name)) { driverClassName = value; } else { throw new RuntimeException(\"[database]: &lt;property&gt; unknown name\"); } } Class.forName(driverClassName); Connection connection = null; try { //建立数据库链接 connection = DriverManager.getConnection(url, username, password); } catch (SQLException e) { // TODO Auto-generated catch block e.printStackTrace(); } return connection; } //获取property属性的值,如果有value值,则读取 没有设置value,则读取内容 private static String getValue(Element node) { return node.hasContent() ? node.getText() : node.attributeValue(\"value\"); } @SuppressWarnings(\"rawtypes\") public MapperBean readMapper(String path) { MapperBean mapper = new MapperBean(); try { InputStream stream = loader.getResourceAsStream(path); SAXReader reader = new SAXReader(); Document document = reader.read(stream); Element root = document.getRootElement(); //把mapper节点的nameSpace值存为接口名 mapper.setInterfaceName(root.attributeValue(\"nameSpace\").trim()); //用来存储方法的List List&lt;Function&gt; list = new ArrayList&lt;Function&gt;(); for (Iterator rootIter = root.elementIterator(); rootIter.hasNext(); ) { //遍历根节点下所有子节点 //用来存储一条方法的信息 Function fun = new Function(); Element e = (Element) rootIter.next(); String sqltype = e.getName().trim(); String funcName = e.attributeValue(\"id\").trim(); String sql = e.getText().trim(); String resultType = e.attributeValue(\"resultType\").trim(); fun.setSqltype(sqltype); fun.setFuncName(funcName); Object newInstance = null; try { newInstance = Class.forName(resultType).newInstance(); } catch (InstantiationException e1) { e1.printStackTrace(); } catch (IllegalAccessException e1) { e1.printStackTrace(); } catch (ClassNotFoundException e1) { e1.printStackTrace(); } fun.setResultType(newInstance); fun.setSql(sql); list.add(fun); } mapper.setList(list); } catch (DocumentException e) { e.printStackTrace(); } return mapper; }} 用面向对象的思想设计读取xml配置后： 12345public class MapperBean { private String interfaceName; //接口名 private List&lt;Function&gt; list; //接口下所有方法 //省略 get set方法...} Function对象包括sql的类型、方法名、sql语句、返回类型和参数类型。 12345678public class Function { private String sqltype; private String funcName; private String sql; private Object resultType; private String parameterType; //省略 get set方法} 接下来实现我们的MySqlSession,首先的成员变量里得有Excutor和MyConfiguration，代码的精髓就在getMapper的方法里。 12345678910111213141516171819public class MySqlsession { private Excutor excutor= new MyExcutor(); private MyConfiguration myConfiguration = new MyConfiguration(); public &lt;T&gt; T selectOne(String statement,Object parameter){ return excutor.query(statement, parameter); } @SuppressWarnings(\"unchecked\") public &lt;T&gt; T getMapper(Class&lt;T&gt; clas){ //动态代理调用 return (T)Proxy.newProxyInstance(clas.getClassLoader(),new Class[]{clas}, new MyMapperProxy(myConfiguration,this)); } } 紧接着创建Excutor和实现类： 123public interface Excutor { public &lt;T&gt; T query(String statement,Object parameter); } MyExcutor中封装了JDBC的操作： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class MyExcutor implements Excutor{ private MyConfiguration xmlConfiguration = new MyConfiguration(); @Override public &lt;T&gt; T query(String sql, Object parameter) { Connection connection=getConnection(); ResultSet set =null; PreparedStatement pre =null; try { pre = connection.prepareStatement(sql); //设置参数 pre.setString(1, parameter.toString()); set = pre.executeQuery(); User u=new User(); //遍历结果集 while(set.next()){ u.setId(set.getString(1)); u.setUsername(set.getString(2)); u.setPassword(set.getString(3)); } return (T) u; } catch (SQLException e) { e.printStackTrace(); } finally{ try{ if(set!=null){ set.close(); }if(pre!=null){ pre.close(); }if(connection!=null){ connection.close(); } }catch(Exception e2){ e2.printStackTrace(); } } return null; } private Connection getConnection() { try { Connection connection =xmlConfiguration.build(\"config.xml\"); return connection; } catch (Exception e) { e.printStackTrace(); } return null; } } MyMapperProxy代理类完成xml方法和真实方法对应，执行查询： 123456789101112131415161718192021222324252627282930public class MyMapperProxy implements InvocationHandler{ private MySqlsession mySqlsession; private MyConfiguration myConfiguration; public MyMapperProxy(MyConfiguration myConfiguration,MySqlsession mySqlsession) { this.myConfiguration=myConfiguration; this.mySqlsession=mySqlsession; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { MapperBean readMapper = myConfiguration.readMapper(\"UserMapper.xml\"); //是否是xml文件对应的接口 if(!method.getDeclaringClass().getName().equals(readMapper.getInterfaceName())){ return null; } List&lt;Function&gt; list = readMapper.getList(); if(null != list || 0 != list.size()){ for (Function function : list) { //id是否和接口方法名一样 if(method.getName().equals(function.getFuncName())){ return mySqlsession.selectOne(function.getSql(), String.valueOf(args[0])); } } } return null; }} 到这里，就完成了自己的Mybatis框架，我们测试一下： 12before invokeUser{userName='123456', id='1', password='yebin'}","link":"/2019/04/12/简化Mybatis框架/"}],"tags":[{"name":"session","slug":"session","link":"/tags/session/"},{"name":"事故","slug":"事故","link":"/tags/事故/"},{"name":"CAP","slug":"CAP","link":"/tags/CAP/"},{"name":"线程池","slug":"线程池","link":"/tags/线程池/"},{"name":"nacos","slug":"nacos","link":"/tags/nacos/"},{"name":"JDBC","slug":"JDBC","link":"/tags/JDBC/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"排查工具","slug":"排查工具","link":"/tags/排查工具/"},{"name":"thread","slug":"thread","link":"/tags/thread/"},{"name":"java随笔","slug":"java随笔","link":"/tags/java随笔/"},{"name":"okHttp","slug":"okHttp","link":"/tags/okHttp/"},{"name":"单点登陆","slug":"单点登陆","link":"/tags/单点登陆/"},{"name":"技术心得","slug":"技术心得","link":"/tags/技术心得/"},{"name":"message","slug":"message","link":"/tags/message/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"学习笔记","slug":"学习笔记","link":"/tags/学习笔记/"},{"name":"設計模式","slug":"設計模式","link":"/tags/設計模式/"},{"name":"分布式","slug":"分布式","link":"/tags/分布式/"},{"name":"json","slug":"json","link":"/tags/json/"},{"name":"SpringMVC","slug":"SpringMVC","link":"/tags/SpringMVC/"},{"name":"Mybatis","slug":"Mybatis","link":"/tags/Mybatis/"}],"categories":[{"name":"java","slug":"java","link":"/categories/java/"},{"name":"中间件","slug":"中间件","link":"/categories/中间件/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"JVM","slug":"JVM","link":"/categories/JVM/"}]}